{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fac2655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_gat_main.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "# ----------- Config -------------------\n",
    "IN_CHANNELS = 18\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- ProtoNet GAT Encoder --------------------\n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "        super().__init__()\n",
    "        self.gnn = GAT(\n",
    "            in_channels=IN_CHANNELS,\n",
    "            hidden_channels=hidden,\n",
    "            out_channels=hidden,\n",
    "            heads=heads,\n",
    "            num_layers=layers,\n",
    "            dropout=dropout,\n",
    "            edge_dim=1,\n",
    "            v2=True,\n",
    "            jk='cat'\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.gnn(x, edge_index, edge_weight=edge_attr)\n",
    "\n",
    "# --------- Episode Sampler --------------------------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# --------- Compute Prototypes ------------------------\n",
    "def compute_prototypes(embeddings, labels, num_classes=4):\n",
    "    prototypes = []\n",
    "    for c in range(num_classes):\n",
    "        class_mask = (labels == c)\n",
    "        if class_mask.sum() == 0:\n",
    "            prototypes.append(torch.zeros_like(embeddings[0]))\n",
    "        else:\n",
    "            prototypes.append(embeddings[class_mask].mean(dim=0))\n",
    "    return torch.stack(prototypes)\n",
    "\n",
    "# --------- Compute Distances ------------------------\n",
    "def euclidean_distance(a, b):\n",
    "    return ((a.unsqueeze(1) - b.unsqueeze(0)) ** 2).sum(dim=2)\n",
    "\n",
    "# --------- Prototypical Loss ------------------------\n",
    "def prototypical_loss(embeddings, labels, prototypes):\n",
    "    dists = euclidean_distance(embeddings, prototypes)\n",
    "    log_p_y = F.log_softmax(-dists, dim=1)\n",
    "    loss = F.nll_loss(log_p_y, labels)\n",
    "    preds = log_p_y.argmax(dim=1)\n",
    "    acc = (preds == labels).float().mean().item()\n",
    "    return loss, acc\n",
    "\n",
    "# --------- Training Loop -----------------------------\n",
    "def proto_train(data_list, encoder, optimizer, n_episodes=500, k_shot=4, q_num=1):\n",
    "    encoder.train()\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        task = random.choice(tasks)\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot, q_num)\n",
    "\n",
    "        support_x, support_y = [], []\n",
    "        for g in support_set:\n",
    "            g = g.to(DEVICE)\n",
    "            emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "            support_x.append(emb)\n",
    "            support_y.append(g.y)\n",
    "        support_x = torch.cat(support_x, dim=0)\n",
    "        support_y = torch.cat(support_y, dim=0)\n",
    "\n",
    "        prototypes = compute_prototypes(support_x, support_y)\n",
    "\n",
    "        query = query_set[0].to(DEVICE)\n",
    "        query_emb = encoder(query.x, query.edge_index, query.edge_attr)\n",
    "        loss, acc = prototypical_loss(query_emb, query.y, prototypes)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(f\"[Episode {episode}] Loss: {loss.item():.4f} | Accuracy: {acc*100:.2f}% | Task: {task}\")\n",
    "\n",
    "# --------- Inference on a Graph -----------------------\n",
    "def proto_predict(encoder, support_set, query_graph):\n",
    "    encoder.eval()\n",
    "    support_x, support_y = [], []\n",
    "\n",
    "    for g in support_set:\n",
    "        g = g.to(DEVICE)\n",
    "        emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "        support_x.append(emb)\n",
    "        support_y.append(g.y)\n",
    "\n",
    "    support_x = torch.cat(support_x, dim=0)\n",
    "    support_y = torch.cat(support_y, dim=0)\n",
    "    prototypes = compute_prototypes(support_x, support_y)\n",
    "\n",
    "    query = query_graph.to(DEVICE)\n",
    "    query_emb = encoder(query.x, query.edge_index, query.edge_attr)\n",
    "    dists = euclidean_distance(query_emb, prototypes)\n",
    "    preds = dists.argmin(dim=1)\n",
    "    return preds.cpu()\n",
    "\n",
    "# # --------- Example Runner -----------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"ðŸ“¥ Loading few-shot dataset...\")\n",
    "#     data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "#     encoder = GATEncoder().to(DEVICE)\n",
    "#     optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "#     print(\"ðŸš€ Starting ProtoNet training...\")\n",
    "#     proto_train(data_list, encoder, optimizer, n_episodes=500)\n",
    "\n",
    "#     print(\"ðŸ’¾ Saving trained encoder...\")\n",
    "#     torch.save(encoder.state_dict(), \"models/proto_gat_encoder.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b306592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading few-shot dataset...\n",
      "ðŸš€ Starting ProtoNet training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\379520254.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data/training_data/training_dataset.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] Loss: 1.0803 | Accuracy: 74.56% | Task: Loan\n",
      "[Episode 10] Loss: 0.7273 | Accuracy: 59.22% | Task: Loan\n",
      "[Episode 20] Loss: 0.6088 | Accuracy: 67.96% | Task: Loan\n",
      "[Episode 30] Loss: 0.4954 | Accuracy: 83.52% | Task: Invoice\n",
      "[Episode 40] Loss: 0.3287 | Accuracy: 87.95% | Task: Invoice\n",
      "[Episode 50] Loss: 0.1261 | Accuracy: 95.29% | Task: Final Bill\n",
      "[Episode 60] Loss: 0.1227 | Accuracy: 93.86% | Task: Loan\n",
      "[Episode 70] Loss: 0.0317 | Accuracy: 99.03% | Task: Loan\n",
      "[Episode 80] Loss: 0.0581 | Accuracy: 97.80% | Task: Invoice\n",
      "[Episode 90] Loss: 0.0220 | Accuracy: 98.70% | Task: Final Bill\n",
      "[Episode 100] Loss: 0.0052 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 110] Loss: 0.0029 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 120] Loss: 0.0057 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 130] Loss: 0.0210 | Accuracy: 99.12% | Task: Loan\n",
      "[Episode 140] Loss: 0.0088 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 150] Loss: 0.0084 | Accuracy: 99.03% | Task: Loan\n",
      "[Episode 160] Loss: 0.0021 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 170] Loss: 0.0016 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 180] Loss: 0.0178 | Accuracy: 98.84% | Task: Final Bill\n",
      "[Episode 190] Loss: 0.0005 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 200] Loss: 0.0051 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 210] Loss: 0.0011 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 220] Loss: 0.0019 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 230] Loss: 0.0088 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 240] Loss: 0.0007 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 250] Loss: 0.0041 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 260] Loss: 0.0097 | Accuracy: 98.90% | Task: Invoice\n",
      "[Episode 270] Loss: 0.0053 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 280] Loss: 0.0005 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 290] Loss: 0.0001 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 300] Loss: 0.0086 | Accuracy: 99.28% | Task: Loan\n",
      "[Episode 310] Loss: 0.0002 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 320] Loss: 0.0009 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 330] Loss: 0.0003 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 340] Loss: 0.0001 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 350] Loss: 0.0000 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 360] Loss: 0.0001 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 370] Loss: 0.0041 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 380] Loss: 0.0007 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 390] Loss: 0.0030 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 400] Loss: 0.0003 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 410] Loss: 0.0013 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 420] Loss: 0.0004 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 430] Loss: 0.0010 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 440] Loss: 0.0010 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 450] Loss: 0.0002 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 460] Loss: 0.0005 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 470] Loss: 0.0001 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 480] Loss: 0.0001 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 490] Loss: 0.0002 | Accuracy: 100.00% | Task: Final Bill\n",
      " Saving trained encoder...\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“¥ Loading few-shot dataset...\")\n",
    "data_list = torch.load(\"data/training_data/training_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "encoder = GATEncoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"ðŸš€ Starting ProtoNet training...\")\n",
    "proto_train(data_list, encoder, optimizer, n_episodes=500)\n",
    "\n",
    "print(\" Saving trained encoder...\")\n",
    "torch.save(encoder.state_dict(), \"models/prototypical/proto_gat_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac577e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_eval.py\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import GAT\n",
    "from sklearn.metrics import classification_report\n",
    "# from proto_gat_main import GATEncoder, proto_predict\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- Load Trained Encoder ---------\n",
    "def load_encoder(model_path):\n",
    "    encoder = GATEncoder().to(DEVICE)\n",
    "    encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    encoder.eval()\n",
    "    return encoder\n",
    "\n",
    "# --------- Load Graphs ---------\n",
    "def load_graphs(path):\n",
    "    return torch.load(path, map_location=DEVICE)\n",
    "\n",
    "# --------- Run Prediction ---------\n",
    "def run_inference(support_path, query_path, model_path):\n",
    "    encoder = load_encoder(model_path)\n",
    "    support_graphs = load_graphs(support_path)\n",
    "    query_graphs = load_graphs(query_path)\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    for i, query_graph in enumerate(query_graphs):\n",
    "        pred = proto_predict(encoder, support_graphs, query_graph)\n",
    "        true_labels = query_graph.y.cpu()\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true_labels)\n",
    "\n",
    "        print(f\"\\nðŸ“„ Query Graph {i+1} Predictions:\")\n",
    "        print(pred.tolist())\n",
    "        value_nodes = (pred == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "        print(f\" VALUE nodes at indices: {value_nodes}\")\n",
    "\n",
    "        # Per-label accuracy for this query graph\n",
    "        print(classification_report(true_labels, pred, zero_division=0))\n",
    "\n",
    "    # Overall classification report across all query graphs\n",
    "    all_preds_flat = torch.cat(all_preds).numpy()\n",
    "    all_trues_flat = torch.cat(all_trues).numpy()\n",
    "    print(\"\\n===== Overall Classification Report (all query graphs) =====\")\n",
    "    print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "# # --------- Main ---------\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_inference(\n",
    "#         support_path=\"data/few-shot-dataset/invoice_support.pt\",\n",
    "#         query_path=\"data/few-shot-dataset/invoice_query.pt\",\n",
    "#         model_path=\"models/proto_gat_encoder.pt\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e847deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\4070017765.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\4070017765.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ Query Graph 1 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           3       1.00      1.00      1.00        91\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      "\n",
      "ðŸ“„ Query Graph 2 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n",
      "\n",
      "ðŸ“„ Query Graph 3 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      "ðŸ“„ Query Graph 4 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           1.00        68\n",
      "   macro avg       1.00      1.00      1.00        68\n",
      "weighted avg       1.00      1.00      1.00        68\n",
      "\n",
      "\n",
      "ðŸ“„ Query Graph 5 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           3       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n",
      "\n",
      "ðŸ“„ Query Graph 6 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "\n",
      "ðŸ“„ Query Graph 7 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "\n",
      "===== Overall Classification Report (all query graphs) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           3       1.00      1.00      1.00       297\n",
      "\n",
      "    accuracy                           1.00       397\n",
      "   macro avg       1.00      1.00      1.00       397\n",
      "weighted avg       1.00      1.00      1.00       397\n",
      "\n",
      "\n",
      "ðŸ“„ Query Graph 7 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "\n",
      "===== Overall Classification Report (all query graphs) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           3       1.00      1.00      1.00       297\n",
      "\n",
      "    accuracy                           1.00       397\n",
      "   macro avg       1.00      1.00      1.00       397\n",
      "weighted avg       1.00      1.00      1.00       397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference and print per-label accuracy and overall accuracy using classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_inference_with_accuracy(support_path, query_path, model_path):\n",
    "    encoder = load_encoder(model_path)\n",
    "    support_graphs = load_graphs(support_path)\n",
    "    query_graphs = load_graphs(query_path)\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    for i, query_graph in enumerate(query_graphs):\n",
    "        pred = proto_predict(encoder, support_graphs, query_graph)\n",
    "        true_labels = query_graph.y.cpu()\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true_labels)\n",
    "\n",
    "        print(f\"\\nðŸ“„ Query Graph {i+1} Predictions:\")\n",
    "        print(pred.tolist())\n",
    "        value_nodes = (pred == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "        print(f\" VALUE nodes at indices: {value_nodes}\")\n",
    "\n",
    "        # Per-label accuracy for this query graph\n",
    "        print(classification_report(true_labels, pred, zero_division=0))\n",
    "\n",
    "    # Overall classification report across all query graphs\n",
    "    all_preds_flat = torch.cat(all_preds).numpy()\n",
    "    all_trues_flat = torch.cat(all_trues).numpy()\n",
    "    print(\"\\n===== Overall Classification Report (all query graphs) =====\")\n",
    "    print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "run_inference_with_accuracy(\n",
    "    support_path=\"datacheckpoint_01 (1).pt\",\n",
    "    query_path=\"data/test_data/test_dataset_02.pt\",\n",
    "    model_path=\"models/prototypical/proto_gat_encoder.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_single_graph_eval.py\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "# from proto_gat_main import GATEncoder, compute_prototypes, euclidean_distance\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- Load Trained GAT Proto Encoder ---------\n",
    "def load_encoder(model_path):\n",
    "    encoder = GATEncoder().to(DEVICE)\n",
    "    encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    encoder.eval()\n",
    "    return encoder\n",
    "\n",
    "# --------- Evaluate Using Graph(s) ---------\n",
    "def evaluate_single_graph(graph_path, model_path, support_ratio=0.2):\n",
    "    print(\"ðŸ“‚ Loading graph(s) from:\", graph_path)\n",
    "    data = torch.load(graph_path, map_location=DEVICE)\n",
    "    encoder = load_encoder(model_path)\n",
    "\n",
    "    from collections import defaultdict\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        print(\"ðŸ”Ž Detected list of graphs. Splitting support/query at graph level.\")\n",
    "        random.shuffle(data)\n",
    "        split = int(support_ratio * len(data))\n",
    "        if split == 0:\n",
    "            split = 1\n",
    "        support_graphs = data[:split]\n",
    "        query_graphs = data[split:]\n",
    "\n",
    "        support_emb, support_y = [], []\n",
    "        for g in support_graphs:\n",
    "            g = g.to(DEVICE)\n",
    "            emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "            support_emb.append(emb)\n",
    "            support_y.append(g.y)\n",
    "        if not support_emb or not support_y:\n",
    "            print(\"No support graphs available. Please check your data or support_ratio.\")\n",
    "            return\n",
    "\n",
    "        support_emb = torch.cat(support_emb, dim=0)\n",
    "        support_y = torch.cat(support_y, dim=0)\n",
    "        prototypes = compute_prototypes(support_emb, support_y)\n",
    "\n",
    "        for i, g in enumerate(query_graphs):\n",
    "            g = g.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "                dists = euclidean_distance(emb, prototypes)\n",
    "                preds = dists.argmin(dim=1).cpu()\n",
    "                all_preds.append(preds)\n",
    "                all_trues.append(g.y.cpu())\n",
    "\n",
    "                value_indices = (preds == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "                print(f\"\\nðŸ“„ Graph {i+1} Predictions:\")\n",
    "                print(preds.tolist())\n",
    "                print(f\"ðŸŽ¯ Predicted VALUE nodes: {value_indices}\")\n",
    "\n",
    "                # Per-label accuracy for this query graph\n",
    "                print(classification_report(g.y.cpu(), preds, zero_division=0))\n",
    "\n",
    "        # Overall classification report across all query graphs\n",
    "        all_preds_flat = torch.cat(all_preds).numpy()\n",
    "        all_trues_flat = torch.cat(all_trues).numpy()\n",
    "        print(\"\\n===== Overall Classification Report (all query graphs) =====\")\n",
    "        print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "    else:\n",
    "        print(\"ðŸ”Ž Detected single graph. Splitting support/query at node level.\")\n",
    "        graph = data\n",
    "        num_nodes = graph.x.size(0)\n",
    "        indices = list(range(num_nodes))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        split = int(support_ratio * num_nodes)\n",
    "        support_idx = indices[:split]\n",
    "        query_idx = indices[split:]\n",
    "\n",
    "        support_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        support_mask[support_idx] = True\n",
    "\n",
    "        query_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        query_mask[query_idx] = True\n",
    "\n",
    "        support_x = graph.x[support_mask]\n",
    "        support_y = graph.y[support_mask]\n",
    "\n",
    "        query_x = graph.x[query_mask]\n",
    "        query_y = graph.y[query_mask]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = encoder(graph.x.to(DEVICE), graph.edge_index.to(DEVICE), graph.edge_attr.to(DEVICE))\n",
    "            support_emb = embeddings[support_mask.to(DEVICE)]\n",
    "            query_emb = embeddings[query_mask.to(DEVICE)]\n",
    "            prototypes = compute_prototypes(support_emb, support_y.to(DEVICE))\n",
    "            dists = euclidean_distance(query_emb, prototypes)\n",
    "            preds = dists.argmin(dim=1).cpu()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_trues.append(query_y.cpu())\n",
    "\n",
    "        print(f\"Evaluation Completed on Single Graph\")\n",
    "        print(f\"Predicted labels: {preds.tolist()}\")\n",
    "        print(f\"True labels: {query_y.tolist()}\")\n",
    "\n",
    "        # Per-label accuracy for this query set\n",
    "        print(classification_report(query_y, preds, zero_division=0))\n",
    "\n",
    "        # Overall (just this graph)\n",
    "        all_preds_flat = torch.cat(all_preds).numpy()\n",
    "        all_trues_flat = torch.cat(all_trues).numpy()\n",
    "        print(\"\\n===== Overall Classification Report (this graph) =====\")\n",
    "        print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "# --------- Main ---------\n",
    "# if __name__ == \"__main__\":\n",
    "#     evaluate_single_graph(\n",
    "#         graph_path=\"data/sample_invoice.pt\",\n",
    "#         model_path=\"models/proto_gat_encoder.pt\",\n",
    "#         support_ratio=0.2\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea0b359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading graph(s) from: data/test_data/test_dataset_01.pt\n",
      "ðŸ”Ž Detected list of graphs. Splitting support/query at graph level.\n",
      "\n",
      "ðŸ“„ Graph 1 Accuracy: 100.00% (227/227)\n",
      "ðŸŽ¯ Predicted VALUE nodes: []\n",
      "\n",
      "ðŸ“„ Graph 2 Accuracy: 100.00% (76/76)\n",
      "ðŸŽ¯ Predicted VALUE nodes: []\n",
      "\n",
      "ðŸ“„ Graph 3 Accuracy: 100.00% (220/220)\n",
      "ðŸŽ¯ Predicted VALUE nodes: []\n",
      "\n",
      "ðŸ“„ Graph 4 Accuracy: 100.00% (81/81)\n",
      "ðŸŽ¯ Predicted VALUE nodes: []\n",
      "\n",
      "âœ… Overall Accuracy across all query graphs: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\1952921763.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path, map_location=DEVICE)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\1952921763.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "evaluate_single_graph(\n",
    "        graph_path=\"data/test_data/test_dataset_01.pt\",\n",
    "        model_path=\"models/prototypical/proto_gat_encoder.pt\",\n",
    "        support_ratio=0.2\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENVGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
