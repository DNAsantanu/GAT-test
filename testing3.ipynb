{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac2655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_gat_main.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "# ----------- Config -------------------\n",
    "IN_CHANNELS = 18\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- ProtoNet GAT Encoder --------------------\n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "        super().__init__()\n",
    "        self.gnn = GAT(\n",
    "            in_channels=IN_CHANNELS,\n",
    "            hidden_channels=hidden,\n",
    "            out_channels=hidden,\n",
    "            heads=heads,\n",
    "            num_layers=layers,\n",
    "            dropout=dropout,\n",
    "            edge_dim=1,\n",
    "            v2=True,\n",
    "            jk='cat'\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.gnn(x, edge_index, edge_weight=edge_attr)\n",
    "\n",
    "# --------- Episode Sampler --------------------------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# --------- Compute Prototypes ------------------------\n",
    "def compute_prototypes(embeddings, labels, num_classes=4):\n",
    "    prototypes = []\n",
    "    for c in range(num_classes):\n",
    "        class_mask = (labels == c)\n",
    "        if class_mask.sum() == 0:\n",
    "            prototypes.append(torch.zeros_like(embeddings[0]))\n",
    "        else:\n",
    "            prototypes.append(embeddings[class_mask].mean(dim=0))\n",
    "    return torch.stack(prototypes)\n",
    "\n",
    "# --------- Compute Distances ------------------------\n",
    "def euclidean_distance(a, b):\n",
    "    return ((a.unsqueeze(1) - b.unsqueeze(0)) ** 2).sum(dim=2)\n",
    "\n",
    "# --------- Prototypical Loss ------------------------\n",
    "def prototypical_loss(embeddings, labels, prototypes):\n",
    "    dists = euclidean_distance(embeddings, prototypes)\n",
    "    log_p_y = F.log_softmax(-dists, dim=1)\n",
    "    loss = F.nll_loss(log_p_y, labels)\n",
    "    preds = log_p_y.argmax(dim=1)\n",
    "    acc = (preds == labels).float().mean().item()\n",
    "    return loss, acc\n",
    "\n",
    "# --------- Training Loop -----------------------------\n",
    "def proto_train(data_list, encoder, optimizer, n_episodes=500, k_shot=4, q_num=1):\n",
    "    encoder.train()\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        task = random.choice(tasks)\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot, q_num)\n",
    "\n",
    "        support_x, support_y = [], []\n",
    "        for g in support_set:\n",
    "            g = g.to(DEVICE)\n",
    "            emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "            support_x.append(emb)\n",
    "            support_y.append(g.y)\n",
    "        support_x = torch.cat(support_x, dim=0)\n",
    "        support_y = torch.cat(support_y, dim=0)\n",
    "\n",
    "        prototypes = compute_prototypes(support_x, support_y)\n",
    "\n",
    "        query = query_set[0].to(DEVICE)\n",
    "        query_emb = encoder(query.x, query.edge_index, query.edge_attr)\n",
    "        loss, acc = prototypical_loss(query_emb, query.y, prototypes)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(f\"[Episode {episode}] Loss: {loss.item():.4f} | Accuracy: {acc*100:.2f}% | Task: {task}\")\n",
    "\n",
    "# --------- Inference on a Graph -----------------------\n",
    "def proto_predict(encoder, support_set, query_graph):\n",
    "    encoder.eval()\n",
    "    support_x, support_y = [], []\n",
    "\n",
    "    for g in support_set:\n",
    "        g = g.to(DEVICE)\n",
    "        emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "        support_x.append(emb)\n",
    "        support_y.append(g.y)\n",
    "\n",
    "    support_x = torch.cat(support_x, dim=0)\n",
    "    support_y = torch.cat(support_y, dim=0)\n",
    "    prototypes = compute_prototypes(support_x, support_y)\n",
    "\n",
    "    query = query_graph.to(DEVICE)\n",
    "    query_emb = encoder(query.x, query.edge_index, query.edge_attr)\n",
    "    dists = euclidean_distance(query_emb, prototypes)\n",
    "    preds = dists.argmin(dim=1)\n",
    "    return preds.cpu()\n",
    "\n",
    "# # --------- Example Runner -----------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"📥 Loading few-shot dataset...\")\n",
    "#     data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "#     encoder = GATEncoder().to(DEVICE)\n",
    "#     optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "#     print(\"🚀 Starting ProtoNet training...\")\n",
    "#     proto_train(data_list, encoder, optimizer, n_episodes=500)\n",
    "\n",
    "#     print(\"💾 Saving trained encoder...\")\n",
    "#     torch.save(encoder.state_dict(), \"models/proto_gat_encoder.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b306592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading few-shot dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\3612794317.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting ProtoNet training...\n",
      "[Episode 0] Loss: 1.1060 | Accuracy: 79.22% | Task: Final Bill\n",
      "[Episode 10] Loss: 0.6212 | Accuracy: 63.24% | Task: Operative Report\n",
      "[Episode 20] Loss: 0.5852 | Accuracy: 74.73% | Task: Invoice\n",
      "[Episode 30] Loss: 0.3274 | Accuracy: 85.29% | Task: Operative Report\n",
      "[Episode 40] Loss: 0.1529 | Accuracy: 97.50% | Task: Operative Report\n",
      "[Episode 50] Loss: 0.1644 | Accuracy: 94.81% | Task: Final Bill\n",
      "[Episode 60] Loss: 0.0287 | Accuracy: 98.53% | Task: Operative Report\n",
      "[Episode 70] Loss: 0.0792 | Accuracy: 97.10% | Task: Final Bill\n",
      "[Episode 80] Loss: 0.0248 | Accuracy: 98.55% | Task: Loan\n",
      "[Episode 90] Loss: 0.0678 | Accuracy: 96.70% | Task: Invoice\n",
      "[Episode 100] Loss: 0.0221 | Accuracy: 99.09% | Task: Background Verification\n",
      "[Episode 110] Loss: 0.0502 | Accuracy: 97.37% | Task: Loan\n",
      "[Episode 120] Loss: 0.0061 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 130] Loss: 0.0102 | Accuracy: 99.43% | Task: Loan\n",
      "[Episode 140] Loss: 0.0044 | Accuracy: 100.00% | Task: Operative Report\n",
      "[Episode 150] Loss: 0.0027 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 160] Loss: 0.0003 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 170] Loss: 0.0300 | Accuracy: 98.77% | Task: Background Verification\n",
      "[Episode 180] Loss: 0.0255 | Accuracy: 99.34% | Task: Invoice\n",
      "[Episode 190] Loss: 0.0008 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 200] Loss: 0.0073 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 210] Loss: 0.0003 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 220] Loss: 0.0004 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 230] Loss: 0.0007 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 240] Loss: 0.0039 | Accuracy: 100.00% | Task: Operative Report\n",
      "[Episode 250] Loss: 0.0008 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 260] Loss: 0.0000 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 270] Loss: 0.0001 | Accuracy: 100.00% | Task: Operative Report\n",
      "[Episode 280] Loss: 0.0016 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 290] Loss: 0.0002 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 300] Loss: 0.0002 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 310] Loss: 0.0008 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 320] Loss: 0.0007 | Accuracy: 100.00% | Task: Background Verification\n",
      "[Episode 330] Loss: 0.0004 | Accuracy: 100.00% | Task: Operative Report\n",
      "[Episode 340] Loss: 0.0022 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 350] Loss: 0.0007 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 360] Loss: 0.0003 | Accuracy: 100.00% | Task: Background Verification\n",
      "[Episode 370] Loss: 0.0044 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 380] Loss: 0.0001 | Accuracy: 100.00% | Task: Background Verification\n",
      "[Episode 390] Loss: 0.0004 | Accuracy: 100.00% | Task: Background Verification\n",
      "[Episode 400] Loss: 0.0002 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 410] Loss: 0.0001 | Accuracy: 100.00% | Task: Operative Report\n",
      "[Episode 420] Loss: 0.0007 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 430] Loss: 0.0005 | Accuracy: 100.00% | Task: Operative Report\n",
      "[Episode 440] Loss: 0.0006 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 450] Loss: 0.0039 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 460] Loss: 0.0044 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 470] Loss: 0.0000 | Accuracy: 100.00% | Task: Operative Report\n",
      "[Episode 480] Loss: 0.0003 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 490] Loss: 0.0006 | Accuracy: 100.00% | Task: Operative Report\n",
      "💾 Saving trained encoder...\n"
     ]
    }
   ],
   "source": [
    "print(\"📥 Loading few-shot dataset...\")\n",
    "data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "encoder = GATEncoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"🚀 Starting ProtoNet training...\")\n",
    "proto_train(data_list, encoder, optimizer, n_episodes=500)\n",
    "\n",
    "print(\"💾 Saving trained encoder...\")\n",
    "torch.save(encoder.state_dict(), \"models/proto_gat_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac577e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_eval.py\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import GAT\n",
    "# from proto_gat_main import GATEncoder, proto_predict\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- Load Trained Encoder ---------\n",
    "def load_encoder(model_path):\n",
    "    encoder = GATEncoder().to(DEVICE)\n",
    "    encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    encoder.eval()\n",
    "    return encoder\n",
    "\n",
    "# --------- Load Graphs ---------\n",
    "def load_graphs(path):\n",
    "    return torch.load(path, map_location=DEVICE)\n",
    "\n",
    "# --------- Run Prediction ---------\n",
    "def run_inference(support_path, query_path, model_path):\n",
    "    encoder = load_encoder(model_path)\n",
    "    support_graphs = load_graphs(support_path)\n",
    "    query_graphs = load_graphs(query_path)\n",
    "\n",
    "    total_correct = 0\n",
    "    total_nodes = 0\n",
    "\n",
    "    for i, query_graph in enumerate(query_graphs):\n",
    "        pred = proto_predict(encoder, support_graphs, query_graph)\n",
    "        print(f\"\\n📄 Query Graph {i+1} Predictions:\")\n",
    "        print(pred.tolist())\n",
    "        value_nodes = (pred == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "        print(f\" VALUE nodes at indices: {value_nodes}\")\n",
    "\n",
    "        # Compute accuracy for this query graph if ground truth is available\n",
    "        if hasattr(query_graph, 'y') and query_graph.y is not None:\n",
    "            correct = (pred == query_graph.y.cpu()).sum().item()\n",
    "            total = query_graph.y.size(0)\n",
    "            acc = correct / total if total > 0 else 0.0\n",
    "            print(f\" Accuracy: {acc*100:.2f}% ({correct}/{total})\")\n",
    "            total_correct += correct\n",
    "            total_nodes += total\n",
    "\n",
    "    if total_nodes > 0:\n",
    "        overall_acc = total_correct / total_nodes\n",
    "        print(f\"\\n✅ Overall Accuracy across all query graphs: {overall_acc*100:.2f}% ({total_correct}/{total_nodes})\")\n",
    "    else:\n",
    "        print(\"No ground truth labels found in query graphs for accuracy calculation.\")\n",
    "\n",
    "# # --------- Main ---------\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_inference(\n",
    "#         support_path=\"data/few-shot-dataset/invoice_support.pt\",\n",
    "#         query_path=\"data/few-shot-dataset/invoice_query.pt\",\n",
    "#         model_path=\"models/proto_gat_encoder.pt\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e847deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Query Graph 1 Predictions:\n",
      "[0, 1, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 1, 2, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 1, 0, 2, 1, 0, 2, 3, 2, 3, 0, 2, 2, 3, 0, 2, 3, 2, 3, 0, 2, 3, 3, 0, 2, 3, 2, 3, 0, 2, 3, 3, 0, 2, 2, 2, 1, 0, 2, 2, 1, 0, 2, 2, 1, 0, 2, 2, 1, 0, 3, 1, 1, 0, 2, 3, 1, 0, 3, 2, 0, 3, 3, 1, 0, 2, 2, 3, 0, 2, 3, 3, 0, 2, 3, 1, 0, 2, 1]\n",
      " VALUE nodes at indices: [1, 4, 8, 12, 14, 16, 20, 24, 28, 32, 53, 56, 88, 92, 96, 100, 103, 104, 108, 115, 127, 130]\n",
      " Accuracy: 40.46% (53/131)\n",
      "\n",
      "✅ Overall Accuracy across all query graphs: 40.46% (53/131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\1790523636.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\1790523636.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path, map_location=DEVICE)\n"
     ]
    }
   ],
   "source": [
    "# Run inference and print accuracy for each query graph and overall accuracy\n",
    "def run_inference_with_accuracy(support_path, query_path, model_path):\n",
    "    encoder = load_encoder(model_path)\n",
    "    support_graphs = load_graphs(support_path)\n",
    "    query_graphs = load_graphs(query_path)\n",
    "\n",
    "    total_correct = 0\n",
    "    total_nodes = 0\n",
    "\n",
    "    for i, query_graph in enumerate(query_graphs):\n",
    "        pred = proto_predict(encoder, support_graphs, query_graph)\n",
    "        true_labels = query_graph.y.cpu()\n",
    "        correct = (pred == true_labels).sum().item()\n",
    "        total = true_labels.size(0)\n",
    "        acc = correct / total if total > 0 else 0.0\n",
    "        total_correct += correct\n",
    "        total_nodes += total\n",
    "\n",
    "        print(f\"\\n📄 Query Graph {i+1} Predictions:\")\n",
    "        print(pred.tolist())\n",
    "        value_nodes = (pred == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "        print(f\" VALUE nodes at indices: {value_nodes}\")\n",
    "        print(f\" Accuracy: {acc*100:.2f}% ({correct}/{total})\")\n",
    "\n",
    "    overall_acc = total_correct / total_nodes if total_nodes > 0 else 0.0\n",
    "    print(f\"\\n✅ Overall Accuracy across all query graphs: {overall_acc*100:.2f}% ({total_correct}/{total_nodes})\")\n",
    "\n",
    "run_inference_with_accuracy(\n",
    "    support_path=\"datacheckpoint_training_(15).pt\",\n",
    "    query_path=\"BG/datacheckpoint_10.pt\",\n",
    "    model_path=\"models/proto_gat_encoder.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dce678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_single_graph_eval.py\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "# from proto_gat_main import GATEncoder, compute_prototypes, euclidean_distance\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- Load Trained GAT Proto Encoder ---------\n",
    "def load_encoder(model_path):\n",
    "    encoder = GATEncoder().to(DEVICE)\n",
    "    encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    encoder.eval()\n",
    "    return encoder\n",
    "\n",
    "# --------- Evaluate Using Graph(s) ---------\n",
    "def evaluate_single_graph(graph_path, model_path, support_ratio=0.2):\n",
    "    print(\"📂 Loading graph(s) from:\", graph_path)\n",
    "    data = torch.load(graph_path, map_location=DEVICE)\n",
    "    encoder = load_encoder(model_path)\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        print(\"🔎 Detected list of graphs. Splitting support/query at graph level.\")\n",
    "        random.shuffle(data)\n",
    "        split = int(support_ratio * len(data))\n",
    "        if split == 0:\n",
    "            split = 1\n",
    "        support_graphs = data[:split]\n",
    "        query_graphs = data[split:]\n",
    "\n",
    "        support_emb, support_y = [], []\n",
    "        for g in support_graphs:\n",
    "            g = g.to(DEVICE)\n",
    "            emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "            support_emb.append(emb)\n",
    "            support_y.append(g.y)\n",
    "        if not support_emb or not support_y:\n",
    "            print(\"❌ No support graphs available. Please check your data or support_ratio.\")\n",
    "            return\n",
    "\n",
    "        support_emb = torch.cat(support_emb, dim=0)\n",
    "        support_y = torch.cat(support_y, dim=0)\n",
    "        prototypes = compute_prototypes(support_emb, support_y)\n",
    "\n",
    "        total_correct, total_nodes = 0, 0\n",
    "        for i, g in enumerate(query_graphs):\n",
    "            g = g.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "                dists = euclidean_distance(emb, prototypes)\n",
    "                preds = dists.argmin(dim=1).cpu()\n",
    "                correct = (preds == g.y.cpu()).sum().item()\n",
    "                total = g.y.size(0)\n",
    "                acc = correct / total if total > 0 else 0.0\n",
    "                total_correct += correct\n",
    "                total_nodes += total\n",
    "\n",
    "                value_indices = (preds == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "                print(f\"\\n📄 Graph {i+1} Accuracy: {acc*100:.2f}% ({correct}/{total})\")\n",
    "                print(f\"🎯 Predicted VALUE nodes: {value_indices}\")\n",
    "\n",
    "        overall_acc = total_correct / total_nodes if total_nodes > 0 else 0.0\n",
    "        print(f\"\\n✅ Overall Accuracy across all query graphs: {overall_acc*100:.2f}%\")\n",
    "\n",
    "    else:\n",
    "        print(\"🔎 Detected single graph. Splitting support/query at node level.\")\n",
    "        graph = data\n",
    "        num_nodes = graph.x.size(0)\n",
    "        indices = list(range(num_nodes))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        split = int(support_ratio * num_nodes)\n",
    "        support_idx = indices[:split]\n",
    "        query_idx = indices[split:]\n",
    "\n",
    "        support_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        support_mask[support_idx] = True\n",
    "\n",
    "        query_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        query_mask[query_idx] = True\n",
    "\n",
    "        support_x = graph.x[support_mask]\n",
    "        support_y = graph.y[support_mask]\n",
    "\n",
    "        query_x = graph.x[query_mask]\n",
    "        query_y = graph.y[query_mask]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = encoder(graph.x.to(DEVICE), graph.edge_index.to(DEVICE), graph.edge_attr.to(DEVICE))\n",
    "            support_emb = embeddings[support_mask.to(DEVICE)]\n",
    "            query_emb = embeddings[query_mask.to(DEVICE)]\n",
    "            prototypes = compute_prototypes(support_emb, support_y.to(DEVICE))\n",
    "            dists = euclidean_distance(query_emb, prototypes)\n",
    "            preds = dists.argmin(dim=1).cpu()\n",
    "\n",
    "        correct = (preds == query_y).sum().item()\n",
    "        total = len(query_y)\n",
    "        acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "        print(f\"Evaluation Completed on Single Graph\")\n",
    "        print(f\"Accuracy on Query Nodes: {acc*100:.2f}% ({correct}/{total})\")\n",
    "\n",
    "        value_indices = (preds == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "        print(f\"Predicted VALUE nodes in query set: {value_indices}\")\n",
    "\n",
    "# --------- Main ---------\n",
    "# if __name__ == \"__main__\":\n",
    "#     evaluate_single_graph(\n",
    "#         graph_path=\"data/sample_invoice.pt\",\n",
    "#         model_path=\"models/proto_gat_encoder.pt\",\n",
    "#         support_ratio=0.2\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea0b359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loading graph(s) from: datacheckpoint_01 (1).pt\n",
      "🔎 Detected list of graphs. Splitting support/query at graph level.\n",
      "\n",
      "✅ Overall Accuracy across all query graphs: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\1900598324.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path, map_location=DEVICE)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_33060\\1900598324.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "evaluate_single_graph(\n",
    "        graph_path=\"datacheckpoint_01 (1).pt\",\n",
    "        model_path=\"models/proto_gat_encoder.pt\",\n",
    "        support_ratio=0.2\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENVGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
