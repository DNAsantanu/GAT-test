{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fac2655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_gat_main.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "# ----------- Config -------------------\n",
    "IN_CHANNELS = 18\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- ProtoNet GAT Encoder --------------------\n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, hidden=256, heads=8, dropout=0.2, layers=2):\n",
    "        super().__init__()\n",
    "        self.gnn = GAT(\n",
    "            in_channels=IN_CHANNELS,\n",
    "            hidden_channels=hidden,\n",
    "            out_channels=hidden,\n",
    "            heads=heads,\n",
    "            num_layers=layers,\n",
    "            dropout=dropout,\n",
    "            edge_dim=1,\n",
    "            v2=True,\n",
    "            jk='cat'\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.gnn(x, edge_index, edge_weight=edge_attr)\n",
    "\n",
    "# --------- Episode Sampler --------------------------\n",
    "def sample_episode(data_list, task, k_shot=1,q_num=4):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# --------- Compute Prototypes ------------------------\n",
    "def compute_prototypes(embeddings, labels, num_classes=4):\n",
    "    prototypes = []\n",
    "    for c in range(num_classes):\n",
    "        class_mask = (labels == c)\n",
    "        if class_mask.sum() == 0:\n",
    "            prototypes.append(torch.zeros_like(embeddings[0]))\n",
    "        else:\n",
    "            prototypes.append(embeddings[class_mask].mean(dim=0))\n",
    "    return torch.stack(prototypes)\n",
    "\n",
    "# --------- Compute Distances ------------------------\n",
    "def euclidean_distance(a, b):\n",
    "    return ((a.unsqueeze(1) - b.unsqueeze(0)) ** 2).sum(dim=2)\n",
    "\n",
    "# --------- Prototypical Loss ------------------------\n",
    "def prototypical_loss(embeddings, labels, prototypes):\n",
    "    dists = euclidean_distance(embeddings, prototypes)\n",
    "    log_p_y = F.log_softmax(-dists, dim=1)\n",
    "    loss = F.nll_loss(log_p_y, labels)\n",
    "    preds = log_p_y.argmax(dim=1)\n",
    "    acc = (preds == labels).float().mean().item()\n",
    "    return loss, acc\n",
    "\n",
    "# --------- Training Loop -----------------------------\n",
    "def proto_train(data_list, encoder, optimizer, n_episodes=500, k_shot=1,q_num=4):\n",
    "    encoder.train()\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        task = random.choice(tasks)\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot, q_num)\n",
    "\n",
    "        support_x, support_y = [], []\n",
    "        for g in support_set:\n",
    "            g = g.to(DEVICE)\n",
    "            emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "            support_x.append(emb)\n",
    "            support_y.append(g.y)\n",
    "        support_x = torch.cat(support_x, dim=0)\n",
    "        support_y = torch.cat(support_y, dim=0)\n",
    "\n",
    "        prototypes = compute_prototypes(support_x, support_y)\n",
    "\n",
    "        query = query_set[0].to(DEVICE)\n",
    "        query_emb = encoder(query.x, query.edge_index, query.edge_attr)\n",
    "        loss, acc = prototypical_loss(query_emb, query.y, prototypes)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(f\"[Episode {episode}] Loss: {loss.item():.4f} | Accuracy: {acc*100:.2f}% | Task: {task}\")\n",
    "\n",
    "# --------- Inference on a Graph -----------------------\n",
    "def proto_predict(encoder, support_set, query_graph):\n",
    "    encoder.eval()\n",
    "    support_x, support_y = [], []\n",
    "\n",
    "    for g in support_set:\n",
    "        g = g.to(DEVICE)\n",
    "        emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "        support_x.append(emb)\n",
    "        support_y.append(g.y)\n",
    "\n",
    "    support_x = torch.cat(support_x, dim=0)\n",
    "    support_y = torch.cat(support_y, dim=0)\n",
    "    prototypes = compute_prototypes(support_x, support_y)\n",
    "\n",
    "    query = query_graph.to(DEVICE)\n",
    "    query_emb = encoder(query.x, query.edge_index, query.edge_attr)\n",
    "    dists = euclidean_distance(query_emb, prototypes)\n",
    "    preds = dists.argmin(dim=1)\n",
    "    return preds.cpu()\n",
    "\n",
    "# # --------- Example Runner -----------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"📥 Loading few-shot dataset...\")\n",
    "#     data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "#     encoder = GATEncoder().to(DEVICE)\n",
    "#     optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "#     print(\"🚀 Starting ProtoNet training...\")\n",
    "#     proto_train(data_list, encoder, optimizer, n_episodes=500)\n",
    "\n",
    "#     print(\"💾 Saving trained encoder...\")\n",
    "#     torch.save(encoder.state_dict(), \"models/proto_gat_encoder.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b306592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading few-shot dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13212\\1554378794.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data/training_data/training_dataset.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting ProtoNet training...\n",
      "[Episode 0] Loss: 0.9421 | Accuracy: 76.32% | Task: Loan\n",
      "[Episode 10] Loss: 0.6295 | Accuracy: 66.28% | Task: Final Bill\n",
      "[Episode 20] Loss: 0.3593 | Accuracy: 90.91% | Task: Loan\n",
      "[Episode 30] Loss: 0.2240 | Accuracy: 93.02% | Task: Final Bill\n",
      "[Episode 40] Loss: 0.1299 | Accuracy: 96.19% | Task: Final Bill\n",
      "[Episode 50] Loss: 0.0562 | Accuracy: 98.82% | Task: Final Bill\n",
      "[Episode 60] Loss: 0.0162 | Accuracy: 99.43% | Task: Loan\n",
      "[Episode 70] Loss: 0.0113 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 80] Loss: 0.0668 | Accuracy: 98.06% | Task: Loan\n",
      "[Episode 90] Loss: 0.0290 | Accuracy: 98.10% | Task: Final Bill\n",
      "[Episode 100] Loss: 0.0036 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 110] Loss: 0.0004 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 120] Loss: 0.0109 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 130] Loss: 0.0110 | Accuracy: 98.80% | Task: Invoice\n",
      "[Episode 140] Loss: 0.0114 | Accuracy: 99.16% | Task: Invoice\n",
      "[Episode 150] Loss: 0.0014 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 160] Loss: 0.0030 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 170] Loss: 0.0000 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 180] Loss: 0.0000 | Accuracy: 100.00% | Task: Final Bill\n",
      "[Episode 190] Loss: 0.0009 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 200] Loss: 0.0000 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 210] Loss: 0.0003 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 220] Loss: 0.0002 | Accuracy: 100.00% | Task: Loan\n",
      "[Episode 230] Loss: 0.0071 | Accuracy: 100.00% | Task: Invoice\n",
      "[Episode 240] Loss: 0.0002 | Accuracy: 100.00% | Task: Invoice\n",
      " Saving trained encoder...\n"
     ]
    }
   ],
   "source": [
    "print(\"📥 Loading few-shot dataset...\")\n",
    "data_list = torch.load(\"data/training_data/training_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "encoder = GATEncoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "# -------- Load pretrained weights here ----------\n",
    "# pretrained_path = \"models\\\\model\\\\SingleRun_H256_L2_HD8_DO2.pth\"  # <-- Update path if needed\n",
    "# print(f\"🔁 Loading pretrained weights from {pretrained_path}\")\n",
    "# encoder.load_state_dict(torch.load(pretrained_path, map_location=DEVICE))\n",
    "\n",
    "# ✅ Optional: freeze layers if you don’t want to fine-tune\n",
    "# for param in encoder.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"🚀 Starting ProtoNet training...\")\n",
    "proto_train(data_list, encoder, optimizer, n_episodes=250)\n",
    "\n",
    "print(\" Saving trained encoder...\")\n",
    "torch.save(encoder.state_dict(), \"models/prototypical/proto_gat_encoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac577e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_eval.py\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import GAT\n",
    "from sklearn.metrics import classification_report\n",
    "# from proto_gat_main import GATEncoder, proto_predict\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- Load Trained Encoder ---------\n",
    "def load_encoder(model_path):\n",
    "    encoder = GATEncoder().to(DEVICE)\n",
    "    encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    encoder.eval()\n",
    "    return encoder\n",
    "\n",
    "# --------- Load Graphs ---------\n",
    "def load_graphs(path):\n",
    "    return torch.load(path, map_location=DEVICE)\n",
    "\n",
    "# --------- Run Prediction ---------\n",
    "def run_inference(support_path, query_path, model_path):\n",
    "    encoder = load_encoder(model_path)\n",
    "    support_graphs = load_graphs(support_path)\n",
    "    query_graphs = load_graphs(query_path)\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    for i, query_graph in enumerate(query_graphs):\n",
    "        pred = proto_predict(encoder, support_graphs, query_graph)\n",
    "        true_labels = query_graph.y.cpu()\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true_labels)\n",
    "\n",
    "        print(f\"\\n📄 Query Graph {i+1} Predictions:\")\n",
    "        print(pred.tolist())\n",
    "        value_nodes = (pred == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "        print(f\" VALUE nodes at indices: {value_nodes}\")\n",
    "\n",
    "        # Per-label accuracy for this query graph\n",
    "        print(classification_report(true_labels, pred, zero_division=0))\n",
    "\n",
    "    # Overall classification report across all query graphs\n",
    "    all_preds_flat = torch.cat(all_preds).numpy()\n",
    "    all_trues_flat = torch.cat(all_trues).numpy()\n",
    "    print(\"\\n===== Overall Classification Report (all query graphs) =====\")\n",
    "    print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "# # --------- Main ---------\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_inference(\n",
    "#         support_path=\"data/few-shot-dataset/invoice_support.pt\",\n",
    "#         query_path=\"data/few-shot-dataset/invoice_query.pt\",\n",
    "#         model_path=\"models/proto_gat_encoder.pt\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e847deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13212\\4070017765.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13212\\4070017765.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Query Graph 1 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           3       1.00      1.00      1.00        91\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      "\n",
      "📄 Query Graph 2 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n",
      "\n",
      "📄 Query Graph 3 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      "📄 Query Graph 4 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           1.00        68\n",
      "   macro avg       1.00      1.00      1.00        68\n",
      "weighted avg       1.00      1.00      1.00        68\n",
      "\n",
      "\n",
      "📄 Query Graph 5 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           3       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n",
      "\n",
      "📄 Query Graph 6 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "\n",
      "📄 Query Graph 7 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]\n",
      " VALUE nodes at indices: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "\n",
      "===== Overall Classification Report (all query graphs) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           3       1.00      1.00      1.00       297\n",
      "\n",
      "    accuracy                           1.00       397\n",
      "   macro avg       1.00      1.00      1.00       397\n",
      "weighted avg       1.00      1.00      1.00       397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference and print per-label accuracy and overall accuracy using classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run_inference_with_accuracy(support_path, query_path, model_path):\n",
    "    encoder = load_encoder(model_path)\n",
    "    support_graphs = load_graphs(support_path)\n",
    "    query_graphs = load_graphs(query_path)\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    for i, query_graph in enumerate(query_graphs):\n",
    "        pred = proto_predict(encoder, support_graphs, query_graph)\n",
    "        true_labels = query_graph.y.cpu()\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true_labels)\n",
    "\n",
    "        print(f\"\\n📄 Query Graph {i+1} Predictions:\")\n",
    "        print(pred.tolist())\n",
    "        value_nodes = (pred == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "        print(f\" VALUE nodes at indices: {value_nodes}\")\n",
    "\n",
    "        # Per-label accuracy for this query graph\n",
    "        print(classification_report(true_labels, pred, zero_division=0))\n",
    "\n",
    "    # Overall classification report across all query graphs\n",
    "    all_preds_flat = torch.cat(all_preds).numpy()\n",
    "    all_trues_flat = torch.cat(all_trues).numpy()\n",
    "    print(\"\\n===== Overall Classification Report (all query graphs) =====\")\n",
    "    print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "run_inference_with_accuracy(\n",
    "    support_path=\"data\\\\final_bill\\\\datacheckpoint_1.pt\",\n",
    "    query_path=\"data/test_data/test_dataset_OR.pt\",\n",
    "    model_path=\"models/prototypical/proto_gat_encoder.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c28b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13212\\4070017765.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13212\\4070017765.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📄 Query Graph 1 Predictions:\n",
      "[0, 1, 3, 0, 1, 3, 0, 1, 3, 0, 1, 3, 0, 1, 2, 2, 2, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 1, 3, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 3, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 3, 2, 2, 1, 1, 0, 2, 1, 3, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 1]\n",
      " VALUE nodes at indices: [1, 4, 7, 10, 13, 17, 18, 21, 26, 27, 30, 31, 34, 39, 40, 43, 44, 47, 48, 52, 53, 56, 57, 59, 63, 64, 68, 69, 72, 73, 76, 81, 82, 86, 87, 91, 92, 95, 96, 99, 103, 104, 107, 111, 112, 115, 116, 120, 121, 125, 126, 129, 130, 134, 135, 139, 140, 143, 144, 146]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.65      0.31        17\n",
      "           1       0.23      1.00      0.38        14\n",
      "           2       0.30      0.26      0.28        27\n",
      "           3       0.90      0.10      0.18        89\n",
      "\n",
      "    accuracy                           0.28       147\n",
      "   macro avg       0.41      0.50      0.29       147\n",
      "weighted avg       0.65      0.28      0.23       147\n",
      "\n",
      "\n",
      "📄 Query Graph 2 Predictions:\n",
      "[2, 2, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 1, 3, 0, 0, 1, 1, 0, 0, 1, 3, 0, 2, 1, 3, 0, 2, 1, 3, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1]\n",
      " VALUE nodes at indices: [2, 5, 10, 11, 14, 15, 18, 23, 24, 27, 28, 31, 32, 36, 37, 40, 41, 43, 47, 48, 51, 55, 59, 64, 65, 69, 70, 74, 75, 78, 79, 82, 83, 87, 88, 91, 92, 95, 96, 100, 101, 104, 105, 109, 110, 113, 114, 117, 118, 122, 123, 127, 128, 131, 132]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.71      0.36        17\n",
      "           1       0.25      1.00      0.41        14\n",
      "           2       0.27      0.27      0.27        22\n",
      "           3       1.00      0.07      0.14        80\n",
      "\n",
      "    accuracy                           0.29       133\n",
      "   macro avg       0.44      0.51      0.29       133\n",
      "weighted avg       0.70      0.29      0.22       133\n",
      "\n",
      "\n",
      "📄 Query Graph 3 Predictions:\n",
      "[0, 0, 1, 1, 3, 2, 2, 2, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 1, 1, 0, 0, 1, 3, 0, 0, 1, 3, 0, 2, 1, 3, 0, 2, 1, 3, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 0, 1, 3, 0, 0, 2, 1, 1, 0, 2, 3, 1, 3, 0, 2, 3, 1, 1, 2, 2, 1, 1, 0, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1]\n",
      " VALUE nodes at indices: [2, 3, 8, 9, 12, 17, 18, 21, 22, 25, 30, 31, 34, 35, 38, 39, 42, 43, 47, 48, 51, 52, 55, 59, 63, 67, 71, 72, 75, 76, 80, 81, 85, 86, 90, 91, 94, 95, 99, 104, 105, 109, 114, 115, 118, 119, 123, 128, 129, 132, 133, 136, 137, 141, 142, 145, 146, 149, 150]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.73      0.42        22\n",
      "           1       0.34      0.91      0.49        22\n",
      "           2       0.32      0.24      0.27        34\n",
      "           3       0.67      0.11      0.19        73\n",
      "\n",
      "    accuracy                           0.34       151\n",
      "   macro avg       0.40      0.50      0.34       151\n",
      "weighted avg       0.49      0.34      0.28       151\n",
      "\n",
      "\n",
      "📄 Query Graph 4 Predictions:\n",
      "[0, 0, 0, 1, 3, 0, 0, 1, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 1, 3, 0, 0, 1, 1, 0, 0, 1, 3, 0, 2, 1, 3, 0, 2, 1, 3, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 3, 0, 2, 3, 1, 1, 2, 2, 2, 1, 1, 0, 0, 3, 1, 1, 2, 2, 1, 1, 0, 0, 2, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 2, 0, 1, 1, 2, 2, 0, 1, 1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
      " VALUE nodes at indices: [3, 7, 10, 11, 15, 16, 20, 21, 25, 26, 29, 32, 33, 36, 41, 42, 45, 46, 49, 54, 55, 58, 59, 63, 64, 68, 69, 72, 73, 75, 79, 80, 83, 87, 91, 95, 96, 99, 100, 104, 105, 109, 110, 114, 115, 119, 124, 125, 129, 130, 134, 135, 138, 139, 143, 144, 148, 149, 152, 153, 157, 158, 161, 162, 165, 166, 170, 171, 174, 175, 177, 178, 180, 181]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.70      0.32        20\n",
      "           1       0.22      0.89      0.35        18\n",
      "           2       0.29      0.30      0.30        30\n",
      "           3       0.80      0.07      0.13       114\n",
      "\n",
      "    accuracy                           0.26       182\n",
      "   macro avg       0.38      0.49      0.27       182\n",
      "weighted avg       0.59      0.26      0.20       182\n",
      "\n",
      "\n",
      "📄 Query Graph 5 Predictions:\n",
      "[0, 3, 1, 0, 0, 1, 3, 0, 0, 3, 1, 2, 2, 1, 1, 0, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 3, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 1, 3, 2, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 3, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 3, 1, 3, 0, 2, 1, 3, 2, 2, 1, 1, 0, 0, 3, 1, 1, 0, 2, 1, 3, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1]\n",
      " VALUE nodes at indices: [2, 5, 10, 13, 14, 18, 23, 24, 27, 28, 31, 36, 37, 40, 41, 45, 46, 50, 51, 54, 55, 57, 60, 61, 64, 65, 69, 70, 73, 74, 77, 82, 83, 87, 88, 92, 93, 96, 97, 101, 105, 109, 110, 114, 115, 118, 122, 123, 126, 127, 131, 132, 135, 136, 140, 141, 145, 146, 150, 151, 154, 155]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.71      0.38        21\n",
      "           1       0.18      0.85      0.29        13\n",
      "           2       0.33      0.24      0.28        34\n",
      "           3       0.75      0.10      0.18        88\n",
      "\n",
      "    accuracy                           0.28       156\n",
      "   macro avg       0.38      0.47      0.28       156\n",
      "weighted avg       0.55      0.28      0.24       156\n",
      "\n",
      "\n",
      "===== Overall Classification Report (all query graphs) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.70      0.36        97\n",
      "           1       0.24      0.93      0.38        81\n",
      "           2       0.30      0.26      0.28       147\n",
      "           3       0.80      0.09      0.16       444\n",
      "\n",
      "    accuracy                           0.29       769\n",
      "   macro avg       0.40      0.49      0.30       769\n",
      "weighted avg       0.58      0.29      0.23       769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_inference_with_accuracy(\n",
    "    support_path=\"data/PR2/Datacheckpoint_GAN_Model_16\",\n",
    "    query_path=\"data/test_data/test_dataset_PR2.pt\",\n",
    "    model_path=\"models/prototypical/proto_gat_encoder.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dce678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto_single_graph_eval.py\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "# from proto_gat_main import GATEncoder, compute_prototypes, euclidean_distance\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- Load Trained GAT Proto Encoder ---------\n",
    "def load_encoder(model_path):\n",
    "    encoder = GATEncoder().to(DEVICE)\n",
    "    encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    encoder.eval()\n",
    "    return encoder\n",
    "\n",
    "# --------- Evaluate Using Graph(s) ---------\n",
    "def evaluate_single_graph(graph_path, model_path, support_ratio=0.2):\n",
    "    print(\" Loading graph(s) from:\", graph_path)\n",
    "    data = torch.load(graph_path, map_location=DEVICE)\n",
    "    encoder = load_encoder(model_path)\n",
    "\n",
    "    from collections import defaultdict\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        print(\" Detected list of graphs. Splitting support/query at graph level.\")\n",
    "        random.shuffle(data)\n",
    "        split = int(support_ratio * len(data))\n",
    "        if split == 0:\n",
    "            split = 1\n",
    "        support_graphs = data[:split]\n",
    "        query_graphs = data[split:]\n",
    "\n",
    "        support_emb, support_y = [], []\n",
    "        for g in support_graphs:\n",
    "            g = g.to(DEVICE)\n",
    "            emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "            support_emb.append(emb)\n",
    "            support_y.append(g.y)\n",
    "        if not support_emb or not support_y:\n",
    "            print(\"No support graphs available. Please check your data or support_ratio.\")\n",
    "            return\n",
    "\n",
    "        support_emb = torch.cat(support_emb, dim=0)\n",
    "        support_y = torch.cat(support_y, dim=0)\n",
    "        prototypes = compute_prototypes(support_emb, support_y)\n",
    "\n",
    "        for i, g in enumerate(query_graphs):\n",
    "            g = g.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                emb = encoder(g.x, g.edge_index, g.edge_attr)\n",
    "                dists = euclidean_distance(emb, prototypes)\n",
    "                preds = dists.argmin(dim=1).cpu()\n",
    "                all_preds.append(preds)\n",
    "                all_trues.append(g.y.cpu())\n",
    "\n",
    "                value_indices = (preds == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "                print(f\"\\n Graph {i+1} Predictions:\")\n",
    "                print(preds.tolist())\n",
    "                print(f\" Predicted VALUE nodes: {value_indices}\")\n",
    "\n",
    "                # Per-label accuracy for this query graph\n",
    "                print(classification_report(g.y.cpu(), preds, zero_division=0))\n",
    "\n",
    "        # Overall classification report across all query graphs\n",
    "        all_preds_flat = torch.cat(all_preds).numpy()\n",
    "        all_trues_flat = torch.cat(all_trues).numpy()\n",
    "        print(\"\\n===== Overall Classification Report (all query graphs) =====\")\n",
    "        print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "    else:\n",
    "        print(\"🔎 Detected single graph. Splitting support/query at node level.\")\n",
    "        graph = data\n",
    "        num_nodes = graph.x.size(0)\n",
    "        indices = list(range(num_nodes))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        split = int(support_ratio * num_nodes)\n",
    "        support_idx = indices[:split]\n",
    "        query_idx = indices[split:]\n",
    "\n",
    "        support_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        support_mask[support_idx] = True\n",
    "\n",
    "        query_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        query_mask[query_idx] = True\n",
    "\n",
    "        support_x = graph.x[support_mask]\n",
    "        support_y = graph.y[support_mask]\n",
    "\n",
    "        query_x = graph.x[query_mask]\n",
    "        query_y = graph.y[query_mask]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = encoder(graph.x.to(DEVICE), graph.edge_index.to(DEVICE), graph.edge_attr.to(DEVICE))\n",
    "            support_emb = embeddings[support_mask.to(DEVICE)]\n",
    "            query_emb = embeddings[query_mask.to(DEVICE)]\n",
    "            prototypes = compute_prototypes(support_emb, support_y.to(DEVICE))\n",
    "            dists = euclidean_distance(query_emb, prototypes)\n",
    "            preds = dists.argmin(dim=1).cpu()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_trues.append(query_y.cpu())\n",
    "\n",
    "        print(f\"Evaluation Completed on Single Graph\")\n",
    "        print(f\"Predicted labels: {preds.tolist()}\")\n",
    "        print(f\"True labels: {query_y.tolist()}\")\n",
    "\n",
    "        # Per-label accuracy for this query set\n",
    "        print(classification_report(query_y, preds, zero_division=0))\n",
    "\n",
    "        # Overall (just this graph)\n",
    "        all_preds_flat = torch.cat(all_preds).numpy()\n",
    "        all_trues_flat = torch.cat(all_trues).numpy()\n",
    "        print(\"\\n===== Overall Classification Report (this graph) =====\")\n",
    "        print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "        return all_preds, all_trues\n",
    "\n",
    "\n",
    "# --------- Main ---------\n",
    "# if __name__ == \"__main__\":\n",
    "#     evaluate_single_graph(\n",
    "#         graph_path=\"data/sample_invoice.pt\",\n",
    "#         model_path=\"models/proto_gat_encoder.pt\",\n",
    "#         support_ratio=0.2\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea0b359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading graph(s) from: data/test_data/test_dataset_OR.pt\n",
      " Detected list of graphs. Splitting support/query at graph level.\n",
      "\n",
      " Graph 1 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3]\n",
      " Predicted VALUE nodes: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "\n",
      " Graph 2 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3]\n",
      " Predicted VALUE nodes: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           1.00        68\n",
      "   macro avg       1.00      1.00      1.00        68\n",
      "weighted avg       1.00      1.00      1.00        68\n",
      "\n",
      "\n",
      " Graph 3 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]\n",
      " Predicted VALUE nodes: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13212\\3752521238.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path, map_location=DEVICE)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13212\\3752521238.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      " Graph 4 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3]\n",
      " Predicted VALUE nodes: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           3       1.00      1.00      1.00        91\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      "\n",
      " Graph 5 Predictions:\n",
      "[0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3]\n",
      " Predicted VALUE nodes: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n",
      "\n",
      " Graph 6 Predictions:\n",
      "[0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]\n",
      " Predicted VALUE nodes: []\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "\n",
      "===== Overall Classification Report (all query graphs) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        91\n",
      "           3       1.00      1.00      1.00       274\n",
      "\n",
      "    accuracy                           1.00       365\n",
      "   macro avg       1.00      1.00      1.00       365\n",
      "weighted avg       1.00      1.00      1.00       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_single_graph(\n",
    "        graph_path=\"data/test_data/test_dataset_OR.pt\",\n",
    "        model_path=\"models/prototypical/proto_gat_encoder.pt\",\n",
    "        support_ratio=0.2\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENVGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
