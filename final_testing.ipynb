{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66002d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn.models import GAT\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n",
    "from torch_geometric.data.storage import GlobalStorage\n",
    "import torch.serialization\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f8db16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82d84458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data \n",
    "with torch.serialization.safe_globals([Data]):\n",
    "    data_list = torch.load(\"training_data\\Datacheckpoint_latest_22\", map_location='cuda', weights_only=False)\n",
    "\n",
    "labels = json.load(open(\"label_encoding.json\"))\n",
    "batch_size = 1\n",
    "\n",
    "train_split = int(len(data_list) * 0.8)\n",
    "train_data = data_list[:train_split]\n",
    "val_data = data_list[train_split:]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "in_channels = data_list[0].x.size(1)\n",
    "# in_channels =18\n",
    "num_classes = len(labels)\n",
    "\n",
    "model_dir = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Desktop\\\\GAT-model testing\\\\GAT-test\\\\models\\\\model\"\n",
    "results_dir = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Desktop\\\\GAT-model testing\\\\GAT-test\\\\results\"\n",
    "plots_dir = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Desktop\\\\GAT-model testing\\\\GAT-test\\\\plots\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(plots_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1fa5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    config = {\n",
    "        'hidden_channels': trial.suggest_categorical('hidden_channels', [64, 128, 256]),\n",
    "        'num_layers': trial.suggest_int('num_layers', 1, 3),\n",
    "        'heads': trial.suggest_categorical('heads', [1, 2, 4, 8]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.0, 0.5),\n",
    "        'hidden_dim': trial.suggest_categorical('hidden_dim', [64, 128, 256])\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True):\n",
    "        mlflow.log_params(config)\n",
    "        mlflow.set_tag(\"model\", \"GATv2\")\n",
    "        mlflow.set_tag(\"cv_strategy\", \"StratifiedKFold\")\n",
    "\n",
    "        # all_labels = torch.tensor([data.y.item() for data in data_list])\n",
    "        all_labels = torch.cat([data.y.view(-1) for data in data_list])\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        data_indices = list(range(len(data_list)))\n",
    "\n",
    "        fold_val_acc = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(data_indices, all_labels)):\n",
    "            train_data = [data_list[i] for i in train_idx]\n",
    "            val_data = [data_list[i] for i in val_idx]\n",
    "            train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "            # ----- Model, loss, optimizer setup -----\n",
    "            model = GAT(\n",
    "                in_channels=in_channels,\n",
    "                hidden_channels=config['hidden_channels'],\n",
    "                num_layers=config['num_layers'],\n",
    "                out_channels=num_classes,\n",
    "                dropout=config['dropout'],\n",
    "                heads=config['heads'],\n",
    "                v2=True,\n",
    "                edge_dim=1,\n",
    "                jk='lstm'\n",
    "            ).to(device)\n",
    "\n",
    "            all_train_labels = torch.cat([data.y for data in train_loader.dataset])\n",
    "            class_weights = 1.0 / (torch.bincount(all_train_labels, minlength=num_classes).float() + 1e-6)\n",
    "            class_weights = class_weights / class_weights.sum()\n",
    "            class_weights = class_weights.to(device)\n",
    "\n",
    "            criterion = CrossEntropyLoss(weight=class_weights)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=5e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "\n",
    "            best_val_acc = 0\n",
    "            best_val_loss = float('inf')\n",
    "            wait = 0\n",
    "            patience = 30\n",
    "            min_delta = 1e-4\n",
    "\n",
    "            # Track metrics for this fold\n",
    "            train_acc_list, val_acc_list = [], []\n",
    "            train_loss_list, val_loss_list = [], []\n",
    "\n",
    "            for epoch in range(500):\n",
    "                model.train()\n",
    "                total_loss = 0\n",
    "                correct_train = 0\n",
    "                total_train = 0\n",
    "                for data in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data.x, data.edge_index, edge_weight=data.edge_attr)\n",
    "                    loss = criterion(out, data.y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "                    correct_train += (out.argmax(dim=1) == data.y).sum().item()\n",
    "                    total_train += data.y.size(0)\n",
    "\n",
    "                train_acc = correct_train / total_train\n",
    "                avg_train_loss = total_loss / len(train_loader)\n",
    "                train_acc_list.append(train_acc)\n",
    "                train_loss_list.append(avg_train_loss)\n",
    "\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                correct, total = 0, 0\n",
    "                with torch.no_grad():\n",
    "                    for data in val_loader:\n",
    "                        data = data.to(device)\n",
    "                        out = model(data.x, data.edge_index, edge_weight=data.edge_attr)\n",
    "                        loss = criterion(out, data.y)\n",
    "                        val_loss += loss.item()\n",
    "                        correct += (out.argmax(dim=1) == data.y).sum().item()\n",
    "                        total += data.y.size(0)\n",
    "\n",
    "                avg_val_loss = val_loss / len(val_loader)\n",
    "                val_acc = correct / total\n",
    "                val_acc_list.append(val_acc)\n",
    "                val_loss_list.append(avg_val_loss)\n",
    "\n",
    "                # Print training and validation accuracy per epoch\n",
    "                print(f\"Fold {fold+1} | Epoch {epoch+1:03d} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "                scheduler.step(avg_val_loss)\n",
    "                trial.report(val_acc, epoch)\n",
    "\n",
    "                if avg_val_loss < best_val_loss - min_delta:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    best_val_acc = val_acc\n",
    "                    wait = 0\n",
    "                else:\n",
    "                    wait += 1\n",
    "                    if wait >= patience:\n",
    "                        print(f\" Early stopping at epoch {epoch+1} for fold {fold+1}\")\n",
    "                        break\n",
    "\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            # Save metrics to CSV for this fold\n",
    "            fold_run_name = f\"Trial{trial.number}_Fold{fold+1}_H{config['hidden_channels']}_L{config['num_layers']}_HD{config['heads']}_DO{int(config['dropout']*10)}\"\n",
    "            fold_csv_path = os.path.join(results_dir, f\"{fold_run_name}.csv\")\n",
    "            df = pd.DataFrame({\n",
    "                'Epoch': list(range(1, len(train_acc_list)+1)),\n",
    "                'TrainAcc': train_acc_list,\n",
    "                'ValAcc': val_acc_list,\n",
    "                'TrainLoss': train_loss_list,\n",
    "                'ValLoss': val_loss_list\n",
    "            })\n",
    "            df.to_csv(fold_csv_path, index=False)\n",
    "\n",
    "            print(f\"âœ… Fold {fold+1}: Best Val Acc = {best_val_acc:.4f}\")\n",
    "            fold_val_acc.append(best_val_acc)\n",
    "\n",
    "        mean_val_acc = np.mean(fold_val_acc)\n",
    "        mlflow.log_metric(\"mean_val_acc\", mean_val_acc)\n",
    "        return mean_val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "822a368f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-14 16:42:03,795] A new study created in memory with name: no-name-690c0e8f-7cd9-4c46-ab09-5217386ce23e\n",
      "[W 2025-07-14 16:42:04,069] Trial 0 failed with parameters: {'hidden_channels': 256, 'num_layers': 3, 'heads': 2, 'dropout': 0.24520047567727848, 'hidden_dim': 128} because of the following error: TypeError(\"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\").\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24368\\2898662375.py\", line 22, in objective\n",
      "    for fold, (train_idx, val_idx) in enumerate(skf.split(data_indices, all_labels)):\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\sklearn\\model_selection\\_split.py\", line 881, in split\n",
      "    y = check_array(y, input_name=\"y\", ensure_2d=False, dtype=None)\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1055, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 839, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\torch\\_tensor.py\", line 1149, in __array__\n",
      "    return self.numpy()\n",
      "TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
      "[W 2025-07-14 16:42:04,073] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# print(\"  Accuracy:\", study.best_trial.value)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\optuna\\study\\study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    252\u001b[0m ):\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[21], line 22\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     18\u001b[0m data_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_list)))\n\u001b[0;32m     20\u001b[0m fold_val_acc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mskf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     23\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m [data_list[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_idx]\n\u001b[0;32m     24\u001b[0m     val_data \u001b[38;5;241m=\u001b[39m [data_list[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_idx]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\sklearn\\model_selection\\_split.py:881\u001b[0m, in \u001b[0;36mStratifiedKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m groups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    878\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe groups parameter is ignored by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    880\u001b[0m     )\n\u001b[1;32m--> 881\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\ENVGAT\\lib\\site-packages\\torch\\_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"Best Trial:\")\n",
    "# print(\"  Accuracy:\", study.best_trial.value)\n",
    "print(\"  Params:\")\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(f\"    {k}: {v}\")\n",
    "\n",
    "# === No need to retrain: Best model is already saved during Optuna search ===\n",
    "best_trial = study.best_trial\n",
    "print(\"Best model state_dict saved at:\", best_trial.user_attrs[\"best_model_state_path\"] if \"best_model_state_path\" in best_trial.user_attrs else \"N/A\")\n",
    "print(\"Best full model saved at:\", best_trial.user_attrs[\"best_model_full_path\"] if \"best_model_full_path\" in best_trial.user_attrs else \"N/A\")\n",
    "\n",
    "# Print best train and validation accuracy from all folds for the best trial\n",
    "hidden = best_trial.params['hidden_channels']\n",
    "layers = best_trial.params['num_layers']\n",
    "heads = best_trial.params['heads']\n",
    "dropout = int(best_trial.params['dropout']*10)\n",
    "trial_num = best_trial.number\n",
    "pattern = f\"Trial{trial_num}_Fold*_H{hidden}_L{layers}_HD{heads}_DO{dropout}.csv\"\n",
    "import glob\n",
    "csv_files = glob.glob(os.path.join(\"results\", pattern))\n",
    "best_train_acc = None\n",
    "best_val_acc = None\n",
    "if csv_files:\n",
    "    all_train_acc = []\n",
    "    all_val_acc = []\n",
    "    for csv_path in csv_files:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'TrainAcc' in df:\n",
    "            all_train_acc.append(df['TrainAcc'].max())\n",
    "        if 'ValAcc' in df:\n",
    "            all_val_acc.append(df['ValAcc'].max())\n",
    "    best_train_acc = max(all_train_acc) if all_train_acc else None\n",
    "    best_val_acc = max(all_val_acc) if all_val_acc else None\n",
    "    print(f\"Best Training Accuracy (across folds): {best_train_acc:.4f}\" if best_train_acc is not None else \"Best Training Accuracy: N/A\")\n",
    "    print(f\"Best Validation Accuracy (across folds): {best_val_acc:.4f}\" if best_val_acc is not None else \"Best Validation Accuracy: N/A\")\n",
    "else:\n",
    "    print(f\"Could not find CSV files for best trial with pattern {pattern}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENVGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
