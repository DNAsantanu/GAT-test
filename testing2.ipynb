{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b322c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 5 files for task: Invoice\n",
      "üîç Processing 5 files for task: Loan\n",
      "üîç Processing 5 files for task: Final Bill\n",
      "üîç Processing 5 files for task: Background Verification\n",
      "üîç Processing 7 files for task: Operative Report\n",
      "Saved all 27 graphs to fewshot_dataset.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\2258181699.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Invoice\": \"data/invoice/\",\n",
    "    \"Loan\": \"data/loan/\",\n",
    "    \"Final Bill\": \"data/final_bill/\",\n",
    "    \"Background Verification\": \"data/background_verification/\",\n",
    "    \"Operative Report\": \"data/operative_report/\"\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/few-shot-dataset\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/few-shot-dataset/fewshot_dataset.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to fewshot_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f74971e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 5 files for task: Invoice\n",
      "üîç Processing 5 files for task: Loan\n",
      "üîç Processing 5 files for task: Final Bill\n",
      "üîç Processing 5 files for task: Background Verification\n",
      "üîç Processing 7 files for task: Operative Report\n",
      "Saved all 27 graphs to fewshot_dataset.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\2258181699.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Invoice\": \"data/invoice/\",\n",
    "    \"Loan\": \"data/loan/\",\n",
    "    \"Final Bill\": \"data/final_bill/\",\n",
    "    \"Background Verification\": \"data/background_verification/\",\n",
    "    \"Operative Report\": \"data/operative_report/\"\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/few-shot-dataset\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/few-shot-dataset/fewshot_dataset.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to fewshot_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7eb0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\1680026476.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\")\n"
     ]
    }
   ],
   "source": [
    "data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\")\n",
    "print(data_list[0].task)  # should print \"Invoice\" or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc399b08",
   "metadata": {},
   "source": [
    "### training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c26b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 5 files for task: Invoice\n",
      "üîç Processing 5 files for task: Loan\n",
      "üîç Processing 5 files for task: Final Bill\n",
      "Saved all 15 graphs to training_dataset.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\3500537860.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Invoice\": \"data/invoice/\",\n",
    "    \"Loan\": \"data/loan/\",\n",
    "    \"Final Bill\": \"data/final_bill/\",\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/training_data\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/training_data/training_dataset.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to training_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fdacb",
   "metadata": {},
   "source": [
    "### test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ebb62787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 7 files for task: Operative Report\n",
      "Saved all 7 graphs to test_dataset_OR.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\1430085244.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Operative Report\": \"data/operative_report/\"\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\" Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\"\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/test_data\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/test_data/test_dataset_OR.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to test_dataset_OR.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"PR2\": \"data/PR2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4edfe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maml_runner.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import higher\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "# ------------- Config -------------------\n",
    "IN_CHANNELS = 18\n",
    "OUT_CLASSES = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- GAT Model --------------------\n",
    "def build_gat_model(hidden=256, heads=8, dropout=0.2, layers=2):\n",
    "    return GAT(\n",
    "        in_channels=IN_CHANNELS,\n",
    "        hidden_channels=hidden,\n",
    "        out_channels=OUT_CLASSES,\n",
    "        heads=heads,\n",
    "        num_layers=layers,\n",
    "        dropout=dropout,\n",
    "        edge_dim=1,\n",
    "        v2=True,\n",
    "        jk='lstm'\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# --------- Episode Sampler -------------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    assert len(task_data) >= k_shot + q_num, f\"Not enough data for task: {task}\"\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# --------- MAML Training Loop ----------\n",
    "def maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500, pretrained_path=None):\n",
    "    if pretrained_path:\n",
    "        print(f\"Loading pretrained weights from {pretrained_path}\")\n",
    "        model.load_state_dict(torch.load(pretrained_path, map_location=DEVICE))\n",
    "        \n",
    "    model.train()\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        task = random.choice(tasks)\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot=2, q_num=3)\n",
    "\n",
    "        model.zero_grad()\n",
    "        with torch.backends.cudnn.flags(enabled=False):\n",
    "           with higher.innerloop_ctx(model, optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "           # Inner loop adaptation\n",
    "                for _ in range(inner_steps):\n",
    "                   for support in support_set:\n",
    "                       support = support.to(DEVICE)\n",
    "                       out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                       loss = F.cross_entropy(out, support.y)\n",
    "                       diffopt.step(loss)\n",
    "                # Outer loop: evaluate on query\n",
    "                query = query_set[0].to(DEVICE)\n",
    "                out = fmodel(query.x, query.edge_index, edge_weight=query.edge_attr)\n",
    "                loss = F.cross_entropy(out, query.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        if episode % 5 == 0:\n",
    "            print(f\"[Episode {episode}] Meta-loss: {loss.item():.4f} | Task: {task}\")\n",
    "\n",
    "# --------- MAML Inference -------------\n",
    "def maml_infer(model, support_set, query_doc, optimizer, inner_steps=1):\n",
    "    model.eval()\n",
    "\n",
    "    with higher.innerloop_ctx(model, optimizer, track_higher_grads=False) as (fmodel, diffopt):\n",
    "        # Adapt on support\n",
    "        for _ in range(inner_steps):\n",
    "            for support in support_set:\n",
    "                support = support.to(DEVICE)\n",
    "                out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                loss = F.cross_entropy(out, support.y)\n",
    "                diffopt.step(loss)\n",
    "\n",
    "        # Predict on query\n",
    "        query_doc = query_doc.to(DEVICE)\n",
    "        out = fmodel(query_doc.x, query_doc.edge_index, edge_weight=query_doc.edge_attr)\n",
    "        preds = out.argmax(dim=1)\n",
    "\n",
    "    return preds\n",
    "\n",
    "# def maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500, pretrained_path=None):\n",
    "#     if pretrained_path:\n",
    "#         print(f\" Loading pretrained weights from {pretrained_path}\")\n",
    "#         model.load_state_dict(torch.load(pretrained_path, map_location=DEVICE))\n",
    "\n",
    "\n",
    "# # --------- Main Runner -----------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\" Loading few-shot dataset...\")\n",
    "#     data_list = torch.load(\"data\\few-shot-dataset\\fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "#     model = build_gat_model()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#     print(\" Starting MAML training...\")\n",
    "#     maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500)\n",
    "\n",
    "#     print(\" Saving MAML-trained model...\")\n",
    "#     torch.save(model.state_dict(), \"models\\maml_gat_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27dce39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[147, 18], edge_index=[2, 111], edge_attr=[111, 1], y=[147], task='PR2')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = torch.load(\"data/test_data/test_dataset_PR2.pt\", map_location='cuda', weights_only=False)\n",
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c8fd62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading few-shot dataset...\n",
      " Starting MAML training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\1134076453.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] Meta-loss: 1.1799 | Task: Final Bill\n",
      "[Episode 5] Meta-loss: 0.8459 | Task: Operative Report\n",
      "[Episode 10] Meta-loss: 0.6356 | Task: Loan\n",
      "[Episode 15] Meta-loss: 0.5511 | Task: Operative Report\n",
      "[Episode 20] Meta-loss: 0.5314 | Task: Operative Report\n",
      "[Episode 25] Meta-loss: 0.5353 | Task: Invoice\n",
      "[Episode 30] Meta-loss: 0.5286 | Task: Loan\n",
      "[Episode 35] Meta-loss: 0.5285 | Task: Background Verification\n",
      "[Episode 40] Meta-loss: 0.5015 | Task: Invoice\n",
      "[Episode 45] Meta-loss: 0.4812 | Task: Invoice\n",
      "[Episode 50] Meta-loss: 0.4173 | Task: Invoice\n",
      "[Episode 55] Meta-loss: 0.3618 | Task: Final Bill\n",
      "[Episode 60] Meta-loss: 0.3429 | Task: Background Verification\n",
      "[Episode 65] Meta-loss: 0.2690 | Task: Final Bill\n",
      "[Episode 70] Meta-loss: 0.1608 | Task: Operative Report\n",
      "[Episode 75] Meta-loss: 0.1390 | Task: Loan\n",
      "[Episode 80] Meta-loss: 0.1046 | Task: Loan\n",
      "[Episode 85] Meta-loss: 0.1194 | Task: Loan\n",
      "[Episode 90] Meta-loss: 0.0157 | Task: Operative Report\n",
      "[Episode 95] Meta-loss: 0.0585 | Task: Invoice\n",
      "[Episode 100] Meta-loss: 0.0600 | Task: Background Verification\n",
      "[Episode 105] Meta-loss: 0.0374 | Task: Background Verification\n",
      "[Episode 110] Meta-loss: 0.0052 | Task: Loan\n",
      "[Episode 115] Meta-loss: 0.0130 | Task: Invoice\n",
      "[Episode 120] Meta-loss: 0.0291 | Task: Background Verification\n",
      "[Episode 125] Meta-loss: 0.0038 | Task: Operative Report\n",
      "[Episode 130] Meta-loss: 0.0064 | Task: Final Bill\n",
      "[Episode 135] Meta-loss: 0.0046 | Task: Invoice\n",
      "[Episode 140] Meta-loss: 0.0021 | Task: Final Bill\n",
      "[Episode 145] Meta-loss: 0.0025 | Task: Final Bill\n",
      "[Episode 150] Meta-loss: 0.0035 | Task: Final Bill\n",
      "[Episode 155] Meta-loss: 0.0053 | Task: Loan\n",
      "[Episode 160] Meta-loss: 0.0019 | Task: Background Verification\n",
      "[Episode 165] Meta-loss: 0.0026 | Task: Invoice\n",
      "[Episode 170] Meta-loss: 0.0024 | Task: Loan\n",
      "[Episode 175] Meta-loss: 0.0022 | Task: Operative Report\n",
      "[Episode 180] Meta-loss: 0.0006 | Task: Loan\n",
      "[Episode 185] Meta-loss: 0.0030 | Task: Loan\n",
      "[Episode 190] Meta-loss: 0.0028 | Task: Operative Report\n",
      "[Episode 195] Meta-loss: 0.0025 | Task: Loan\n",
      "[Episode 200] Meta-loss: 0.0018 | Task: Invoice\n",
      "[Episode 205] Meta-loss: 0.0031 | Task: Final Bill\n",
      "[Episode 210] Meta-loss: 0.0064 | Task: Invoice\n",
      "[Episode 215] Meta-loss: 0.0011 | Task: Background Verification\n",
      "[Episode 220] Meta-loss: 0.0004 | Task: Final Bill\n",
      "[Episode 225] Meta-loss: 0.0017 | Task: Background Verification\n",
      "[Episode 230] Meta-loss: 0.0012 | Task: Background Verification\n",
      "[Episode 235] Meta-loss: 0.0015 | Task: Invoice\n",
      "[Episode 240] Meta-loss: 0.0019 | Task: Operative Report\n",
      "[Episode 245] Meta-loss: 0.0014 | Task: Operative Report\n",
      "[Episode 250] Meta-loss: 0.0021 | Task: Background Verification\n",
      "[Episode 255] Meta-loss: 0.0034 | Task: Final Bill\n",
      "[Episode 260] Meta-loss: 0.0016 | Task: Invoice\n",
      "[Episode 265] Meta-loss: 0.0011 | Task: Final Bill\n",
      "[Episode 270] Meta-loss: 0.0011 | Task: Final Bill\n",
      "[Episode 275] Meta-loss: 0.0010 | Task: Loan\n",
      "[Episode 280] Meta-loss: 0.0003 | Task: Invoice\n",
      "[Episode 285] Meta-loss: 0.0001 | Task: Final Bill\n",
      "[Episode 290] Meta-loss: 0.0018 | Task: Invoice\n",
      "[Episode 295] Meta-loss: 0.0003 | Task: Operative Report\n",
      "[Episode 300] Meta-loss: 0.0010 | Task: Loan\n",
      "[Episode 305] Meta-loss: 0.0000 | Task: Operative Report\n",
      "[Episode 310] Meta-loss: 0.0004 | Task: Final Bill\n",
      "[Episode 315] Meta-loss: 0.0022 | Task: Invoice\n",
      "[Episode 320] Meta-loss: 0.0013 | Task: Invoice\n",
      "[Episode 325] Meta-loss: 0.0015 | Task: Final Bill\n",
      "[Episode 330] Meta-loss: 0.0001 | Task: Operative Report\n",
      "[Episode 335] Meta-loss: 0.0006 | Task: Operative Report\n",
      "[Episode 340] Meta-loss: 0.0005 | Task: Final Bill\n",
      "[Episode 345] Meta-loss: 0.0009 | Task: Invoice\n",
      "[Episode 350] Meta-loss: 0.0007 | Task: Invoice\n",
      "[Episode 355] Meta-loss: 0.0003 | Task: Final Bill\n",
      "[Episode 360] Meta-loss: 0.0002 | Task: Loan\n",
      "[Episode 365] Meta-loss: 0.0000 | Task: Operative Report\n",
      "[Episode 370] Meta-loss: 0.0007 | Task: Invoice\n",
      "[Episode 375] Meta-loss: 0.0003 | Task: Invoice\n",
      "[Episode 380] Meta-loss: 0.0006 | Task: Background Verification\n",
      "[Episode 385] Meta-loss: 0.0006 | Task: Background Verification\n",
      "[Episode 390] Meta-loss: 0.0003 | Task: Invoice\n",
      "[Episode 395] Meta-loss: 0.0002 | Task: Operative Report\n",
      "[Episode 400] Meta-loss: 0.0004 | Task: Loan\n",
      "[Episode 405] Meta-loss: 0.0058 | Task: Background Verification\n",
      "[Episode 410] Meta-loss: 0.0002 | Task: Final Bill\n",
      "[Episode 415] Meta-loss: 0.0003 | Task: Background Verification\n",
      "[Episode 420] Meta-loss: 0.0000 | Task: Operative Report\n",
      "[Episode 425] Meta-loss: 0.0003 | Task: Operative Report\n",
      "[Episode 430] Meta-loss: 0.0006 | Task: Invoice\n",
      "[Episode 435] Meta-loss: 0.0008 | Task: Background Verification\n",
      "[Episode 440] Meta-loss: 0.0002 | Task: Final Bill\n",
      "[Episode 445] Meta-loss: 0.0001 | Task: Loan\n",
      "[Episode 450] Meta-loss: 0.0012 | Task: Final Bill\n",
      "[Episode 455] Meta-loss: 0.0000 | Task: Invoice\n",
      "[Episode 460] Meta-loss: 0.0000 | Task: Background Verification\n",
      "[Episode 465] Meta-loss: 0.0001 | Task: Invoice\n",
      "[Episode 470] Meta-loss: 0.0003 | Task: Final Bill\n",
      "[Episode 475] Meta-loss: 0.0005 | Task: Background Verification\n",
      "[Episode 480] Meta-loss: 0.0004 | Task: Background Verification\n",
      "[Episode 485] Meta-loss: 0.0006 | Task: Final Bill\n",
      "[Episode 490] Meta-loss: 0.0002 | Task: Operative Report\n",
      "[Episode 495] Meta-loss: 0.0013 | Task: Invoice\n",
      " Saving MAML-trained model...\n"
     ]
    }
   ],
   "source": [
    "print(\" Loading few-shot dataset...\")\n",
    "data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "model = build_gat_model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(\" Starting MAML training...\")\n",
    "maml_train(data_list, model, optimizer, inner_steps=2, n_episodes=500)\n",
    "\n",
    "# print(\" Starting MAML-training from pretrained model...\")\n",
    "# maml_train(data_list, model, optimizer, inner_steps=2, n_episodes=500, pretrained_path=\"models\\model\\SingleRun_H256_L2_HD8_DO2.pth\")\n",
    "\n",
    "print(\" Saving MAML-trained model...\")\n",
    "torch.save(model.state_dict(), \"models\\maml\\maml_gat_model_without_fine-tuning.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decfb785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "10dbaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maml_evaluator.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GAT\n",
    "import higher\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- GAT Builder (same config as maml_runner) ----------\n",
    "def build_gat_model(hidden=256, heads=8, dropout=0.2, layers=2):\n",
    "    return GAT(\n",
    "        in_channels=18,\n",
    "        hidden_channels=hidden,\n",
    "        out_channels=4,\n",
    "        heads=heads,\n",
    "        num_layers=layers,\n",
    "        dropout=dropout,\n",
    "        edge_dim=1,\n",
    "        v2=True,\n",
    "        jk='lstm'\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# ---------- Episode Sampler ----------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# ---------- Inference Logic ----------\n",
    "def maml_infer(model, support_set, query_doc, optimizer, inner_steps=1):\n",
    "    model.train()\n",
    "\n",
    "    with higher.innerloop_ctx(model, optimizer, track_higher_grads=False) as (fmodel, diffopt):\n",
    "        for _ in range(inner_steps):\n",
    "            for support in support_set:\n",
    "                support = support.to(DEVICE)\n",
    "                out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                loss = F.cross_entropy(out, support.y)\n",
    "                diffopt.step(loss)\n",
    "\n",
    "        query_doc = query_doc.to(DEVICE)\n",
    "        out = fmodel(query_doc.x, query_doc.edge_index, edge_weight=query_doc.edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    return pred.cpu(), query_doc.y.cpu()\n",
    "\n",
    "# ---------- Evaluation Loop ----------\n",
    "def evaluate_model_1(data_list, model_path):\n",
    "    print(\"üîç Loading model...\")\n",
    "    model = build_gat_model()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "    all_preds, all_trues = [], []\n",
    "\n",
    "    for task in tasks:\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot=4, q_num=1)\n",
    "        pred, true = maml_infer(model, support_set, query_set[0], optimizer)\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true)\n",
    "\n",
    "        # Print detection for all labels\n",
    "        unique_labels = set(true.tolist())\n",
    "        detected_labels = set(pred.tolist())\n",
    "        print(f\" Task: {task}\")\n",
    "        print(f\"  True labels present: {sorted(unique_labels)}\")\n",
    "        print(f\"  Predicted labels present: {sorted(detected_labels)}\")\n",
    "        missing_labels = unique_labels - detected_labels\n",
    "        if missing_labels:\n",
    "            print(f\" Missing labels in prediction: {sorted(missing_labels)}\")\n",
    "        else:\n",
    "            print(f\" All true labels detected in prediction.\")\n",
    "\n",
    "        print(f\"  VALUE nodes predicted: {(pred == 1).sum().item()} | True: {(true == 1).sum().item()}\")\n",
    "\n",
    "        # Print classification report for this query\n",
    "        print(classification_report(true, pred, zero_division=0))\n",
    "\n",
    "    # Optionally, print overall classification report\n",
    "    all_preds_flat = torch.cat(all_preds).numpy()\n",
    "    all_trues_flat = torch.cat(all_trues).numpy()\n",
    "    print(\"\\n===== Overall Classification Report (all tasks) =====\")\n",
    "    print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "    return all_preds, all_trues\n",
    "\n",
    "# # ---------- Main Runner ----------\n",
    "# if __name__ == \"__main__\":\n",
    "#     data_list = torch.load(\"fewshot_dataset.pt\", map_location=DEVICE)\n",
    "#     evaluate_model(data_list, model_path=\"maml_gat_model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea5f299",
   "metadata": {},
   "source": [
    " ### fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35c364ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading dataset...\n",
      "üîÅ Loading MAML-trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\2245104132.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(DATA_PATH, map_location=DEVICE)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\2245104132.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "# evaluation.py\n",
    "\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from torch.optim import Adam\n",
    "# from maml_runner import build_gat_model, maml_infer\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_PATH = \"data/test_data/test_dataset_PR2.pt\"\n",
    "MODEL_PATH = \"models/maml/maml_gat_model_fine-tuning.pt\"\n",
    "\n",
    "# ---------------- Load Data ----------------\n",
    "print(\"üì¶ Loading dataset...\")\n",
    "data_list = torch.load(DATA_PATH, map_location=DEVICE)\n",
    "\n",
    "# Group by task\n",
    "task_graphs = defaultdict(list)\n",
    "for graph in data_list:\n",
    "    task_graphs[graph.task].append(graph)\n",
    "\n",
    "# ---------------- Load Model ----------------\n",
    "print(\"üîÅ Loading MAML-trained model...\")\n",
    "model = build_gat_model()\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "\n",
    "# ---------------- Evaluate per Task ----------------\n",
    "model.eval()\n",
    "\n",
    "# for task, graphs in task_graphs.items():\n",
    "#     print(f\"\\nüéØ Evaluating on task: {task} (samples: {len(graphs)})\")\n",
    "\n",
    "#     if len(graphs) < 5:\n",
    "#         print(\"‚ö†Ô∏è Not enough data to evaluate. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     # random.shuffle(graphs)\n",
    "#     k_shot = 1\n",
    "#     support_set = graphs[:k_shot]\n",
    "#     query_set = graphs[k_shot:]\n",
    "\n",
    "#     if len(query_set) == 0:\n",
    "#         print(\"‚ö†Ô∏è No query set available. Skipping.\")\n",
    "#         continue\n",
    "\n",
    "    # correct = 0\n",
    "    # total = 0\n",
    "\n",
    "    # optimizer = Adam(model.parameters(), lr=1e-3)  # Required by maml_infer\n",
    "\n",
    "    # for query_doc in query_set:\n",
    "    #     pred = maml_infer(model, support_set, query_doc, optimizer, inner_steps=1)\n",
    "    #     correct += (pred == query_doc.y).sum().item()\n",
    "    #     total += query_doc.y.size(0)\n",
    "\n",
    "    # acc = correct / total if total > 0 else 0\n",
    "    # print(f\"‚úÖ Accuracy for task '{task}': {acc:.4f}\")\n",
    "\n",
    "# ---------- Episode Sampler ----------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# ---------- Inference Logic ----------\n",
    "def maml_infer(model, support_set, query_doc, optimizer, inner_steps=1):\n",
    "    model.train()\n",
    "\n",
    "    with higher.innerloop_ctx(model, optimizer, track_higher_grads=False) as (fmodel, diffopt):\n",
    "        for _ in range(inner_steps):\n",
    "            for support in support_set:\n",
    "                support = support.to(DEVICE)\n",
    "                out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                loss = F.cross_entropy(out, support.y)\n",
    "                diffopt.step(loss)\n",
    "\n",
    "        query_doc = query_doc.to(DEVICE)\n",
    "        out = fmodel(query_doc.x, query_doc.edge_index, edge_weight=query_doc.edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    return pred.cpu(), query_doc.y.cpu()\n",
    "\n",
    "# ---------- Evaluation Loop ----------\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "# import torch.nn.functional as F\n",
    "# import higher\n",
    "\n",
    "def evaluate_model(data_list, model_path):\n",
    "    print(\"üîç Loading model...\")\n",
    "    model = build_gat_model()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "    all_preds, all_trues = [], []\n",
    "\n",
    "    for task in tasks:\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot=1, q_num=4)\n",
    "        pred, true = maml_infer(model, support_set, query_set[0], optimizer)\n",
    "\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true)\n",
    "\n",
    "        # Task-level analysis\n",
    "        unique_labels = set(true.tolist())\n",
    "        detected_labels = set(pred.tolist())\n",
    "        print(f\" Task: {task}\")\n",
    "        print(f\"  True labels present: {sorted(unique_labels)}\")\n",
    "        print(f\"  Predicted labels present: {sorted(detected_labels)}\")\n",
    "        missing_labels = unique_labels - detected_labels\n",
    "        if missing_labels:\n",
    "            print(f\"  Missing labels in prediction: {sorted(missing_labels)}\")\n",
    "        else:\n",
    "            print(f\"  All true labels detected in prediction.\")\n",
    "        print(f\"  VALUE nodes predicted: {(pred == 1).sum().item()} | True: {(true == 1).sum().item()}\")\n",
    "        print(classification_report(true, pred, zero_division=0))\n",
    "\n",
    "    # Overall evaluation\n",
    "    all_preds_flat = torch.cat(all_preds).numpy()\n",
    "    all_trues_flat = torch.cat(all_trues).numpy()\n",
    "    overall_acc = accuracy_score(all_trues_flat, all_preds_flat)\n",
    "    print(\"\\nüìä Overall Evaluation Across All Tasks\")\n",
    "    print(f\"‚úÖ Overall Accuracy: {overall_acc:.4f}\")\n",
    "    print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "    return all_preds, all_trues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "908f8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "299ae7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_doc.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c8b1c2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\2431143184.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data\\\\test_data\\\\test_dataset_OR.pt\", map_location=DEVICE)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23056\\557839558.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading model...\n",
      " Task: Operative Report\n",
      "  True labels present: [0, 3]\n",
      "  Predicted labels present: [0, 3]\n",
      " All true labels detected in prediction.\n",
      "  VALUE nodes predicted: 0 | True: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "\n",
      "===== Overall Classification Report (all tasks) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 3])],\n",
       " [tensor([0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 3])])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = torch.load(\"data\\\\test_data\\\\test_dataset_OR.pt\", map_location=DEVICE)\n",
    "# evaluate_model(data_list, model_path=\"models\\maml\\maml_gat_model_fine-tuning.pt\")\n",
    "evaluate_model_1(data_list, model_path=\"models\\maml\\maml_gat_model_without_fine-tuning.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89a83454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch_geometric.nn import GAT\n",
    "\n",
    "# DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # ----------- 1. Build the GAT Model ----------\n",
    "# def build_gat_model(hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "#     return GAT(\n",
    "#         in_channels=18,\n",
    "#         hidden_channels=hidden,\n",
    "#         out_channels=4,\n",
    "#         heads=heads,\n",
    "#         num_layers=layers,\n",
    "#         dropout=dropout,\n",
    "#         edge_dim=1,\n",
    "#         v2=True,\n",
    "#         jk='lstm'  # or 'cat' if you trained with that\n",
    "#     ).to(DEVICE)\n",
    "\n",
    "# # ----------- 2. Load Trained Model ----------\n",
    "# model = build_gat_model()\n",
    "# model.load_state_dict(torch.load(\"models/maml/maml_gat_model.pt\", map_location=DEVICE))\n",
    "# model.eval()\n",
    "\n",
    "# # ----------- 3. Load Graphs with Labels ----------\n",
    "# graphs = torch.load(\"BG/datacheckpoint_11.pt\", map_location=DEVICE)\n",
    "\n",
    "# # ----------- 4. Predict + Compare ----------\n",
    "# for i, graph in enumerate(graphs):\n",
    "#     graph = graph.to(DEVICE)\n",
    "#     true_labels = graph.y\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         out = model(graph.x, graph.edge_index, edge_weight=graph.edge_attr)\n",
    "#         pred = out.argmax(dim=1)\n",
    "\n",
    "#     # Compare predictions\n",
    "#     correct = (pred == true_labels).sum().item()\n",
    "#     total = len(true_labels)\n",
    "#     accuracy = correct / total\n",
    "\n",
    "#     # Value-specific analysis\n",
    "#     true_value_indices = (true_labels == 1).nonzero(as_tuple=True)[0]\n",
    "#     pred_value_indices = (pred == 1).nonzero(as_tuple=True)[0]\n",
    "#     true_positive = len(set(pred_value_indices.tolist()) & set(true_value_indices.tolist()))\n",
    "\n",
    "#     print(f\"\\nüìÑ Graph {i+1}:\")\n",
    "#     print(f\"‚úÖ Accuracy: {accuracy*100:.2f}% ({correct}/{total})\")\n",
    "#     print(f\"üîç True VALUE node indices: {true_value_indices.tolist()}\")\n",
    "#     print(f\"üîÆ Predicted VALUE node indices: {pred_value_indices.tolist()}\")\n",
    "#     print(f\"üéØ Correctly predicted VALUEs: {true_positive} / {len(true_value_indices)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENVGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
