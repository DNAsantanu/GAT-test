{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b322c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 5 files for task: Invoice\n",
      "üîç Processing 5 files for task: Loan\n",
      "üîç Processing 5 files for task: Final Bill\n",
      "üîç Processing 5 files for task: Background Verification\n",
      "üîç Processing 5 files for task: Operative Report\n",
      "Saved all 25 graphs to fewshot_dataset.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\2258181699.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Invoice\": \"data/invoice/\",\n",
    "    \"Loan\": \"data/loan/\",\n",
    "    \"Final Bill\": \"data/final_bill/\",\n",
    "    \"Background Verification\": \"data/background_verification/\",\n",
    "    \"Operative Report\": \"data/operative_report/\"\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/few-shot-dataset\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/few-shot-dataset/fewshot_dataset.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to fewshot_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7eb0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\1680026476.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\")\n"
     ]
    }
   ],
   "source": [
    "data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\")\n",
    "print(data_list[0].task)  # should print \"Invoice\" or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26b9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4edfe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maml_runner.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import higher\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "# ------------- Config -------------------\n",
    "IN_CHANNELS = 18\n",
    "OUT_CLASSES = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- GAT Model --------------------\n",
    "def build_gat_model(hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "    return GAT(\n",
    "        in_channels=IN_CHANNELS,\n",
    "        hidden_channels=hidden,\n",
    "        out_channels=OUT_CLASSES,\n",
    "        heads=heads,\n",
    "        num_layers=layers,\n",
    "        dropout=dropout,\n",
    "        edge_dim=1,\n",
    "        v2=True,\n",
    "        jk='lstm'\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# --------- Episode Sampler -------------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    assert len(task_data) >= k_shot + q_num, f\"Not enough data for task: {task}\"\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# --------- MAML Training Loop ----------\n",
    "def maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500):\n",
    "    model.train()\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        task = random.choice(tasks)\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot=4, q_num=1)\n",
    "\n",
    "        model.zero_grad()\n",
    "        with torch.backends.cudnn.flags(enabled=False):\n",
    "           with higher.innerloop_ctx(model, optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "           # Inner loop adaptation\n",
    "                for _ in range(inner_steps):\n",
    "                   for support in support_set:\n",
    "                       support = support.to(DEVICE)\n",
    "                       out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                       loss = F.cross_entropy(out, support.y)\n",
    "                       diffopt.step(loss)\n",
    "                # Outer loop: evaluate on query\n",
    "                query = query_set[0].to(DEVICE)\n",
    "                out = fmodel(query.x, query.edge_index, edge_weight=query.edge_attr)\n",
    "                loss = F.cross_entropy(out, query.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        if episode % 50 == 0:\n",
    "            print(f\"[Episode {episode}] Meta-loss: {loss.item():.4f} | Task: {task}\")\n",
    "\n",
    "# --------- MAML Inference -------------\n",
    "def maml_infer(model, support_set, query_doc, optimizer, inner_steps=1):\n",
    "    model.eval()\n",
    "\n",
    "    with higher.innerloop_ctx(model, optimizer, track_higher_grads=False) as (fmodel, diffopt):\n",
    "        # Adapt on support\n",
    "        for _ in range(inner_steps):\n",
    "            for support in support_set:\n",
    "                support = support.to(DEVICE)\n",
    "                out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                loss = F.cross_entropy(out, support.y)\n",
    "                diffopt.step(loss)\n",
    "\n",
    "        # Predict on query\n",
    "        query_doc = query_doc.to(DEVICE)\n",
    "        out = fmodel(query_doc.x, query_doc.edge_index, edge_weight=query_doc.edge_attr)\n",
    "        preds = out.argmax(dim=1)\n",
    "\n",
    "    return preds\n",
    "\n",
    "# # --------- Main Runner -----------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\" Loading few-shot dataset...\")\n",
    "#     data_list = torch.load(\"data\\few-shot-dataset\\fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "#     model = build_gat_model()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#     print(\" Starting MAML training...\")\n",
    "#     maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500)\n",
    "\n",
    "#     print(\" Saving MAML-trained model...\")\n",
    "#     torch.save(model.state_dict(), \"models\\maml_gat_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c8fd62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading few-shot dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\3847571418.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data\\\\few-shot-dataset\\\\fewshot_dataset.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting MAML training...\n",
      "[Episode 0] Meta-loss: 1.1783 | Task: Loan\n",
      "[Episode 50] Meta-loss: 0.5340 | Task: Loan\n",
      "[Episode 100] Meta-loss: 0.2098 | Task: Invoice\n",
      "[Episode 150] Meta-loss: 0.0344 | Task: Invoice\n",
      "[Episode 200] Meta-loss: 0.0072 | Task: Invoice\n",
      "[Episode 250] Meta-loss: 0.0185 | Task: Invoice\n",
      "[Episode 300] Meta-loss: 0.0068 | Task: Final Bill\n",
      "[Episode 350] Meta-loss: 0.0008 | Task: Loan\n",
      "[Episode 400] Meta-loss: 0.0190 | Task: Loan\n",
      "[Episode 450] Meta-loss: 0.0190 | Task: Final Bill\n",
      " Saving MAML-trained model...\n"
     ]
    }
   ],
   "source": [
    "print(\" Loading few-shot dataset...\")\n",
    "data_list = torch.load(\"data\\\\few-shot-dataset\\\\fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "model = build_gat_model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(\" Starting MAML training...\")\n",
    "maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500)\n",
    "\n",
    "print(\" Saving MAML-trained model...\")\n",
    "torch.save(model.state_dict(), \"models\\maml_gat_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10dbaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maml_evaluator.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GAT\n",
    "import higher\n",
    "import random\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- GAT Builder (same config as maml_runner) ----------\n",
    "def build_gat_model(hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "    return GAT(\n",
    "        in_channels=18,\n",
    "        hidden_channels=hidden,\n",
    "        out_channels=4,\n",
    "        heads=heads,\n",
    "        num_layers=layers,\n",
    "        dropout=dropout,\n",
    "        edge_dim=1,\n",
    "        v2=True,\n",
    "        jk='lstm'\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# ---------- Episode Sampler ----------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# ---------- Inference Logic ----------\n",
    "def maml_infer(model, support_set, query_doc, optimizer, inner_steps=1):\n",
    "    model.train()\n",
    "\n",
    "    with higher.innerloop_ctx(model, optimizer, track_higher_grads=False) as (fmodel, diffopt):\n",
    "        for _ in range(inner_steps):\n",
    "            for support in support_set:\n",
    "                support = support.to(DEVICE)\n",
    "                out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                loss = F.cross_entropy(out, support.y)\n",
    "                diffopt.step(loss)\n",
    "\n",
    "        query_doc = query_doc.to(DEVICE)\n",
    "        out = fmodel(query_doc.x, query_doc.edge_index, edge_weight=query_doc.edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    return pred.cpu(), query_doc.y.cpu()\n",
    "\n",
    "# ---------- Evaluation Loop ----------\n",
    "def evaluate_model(data_list, model_path):\n",
    "    print(\"üîç Loading model...\")\n",
    "    model = build_gat_model()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "    all_preds, all_trues = [], []\n",
    "\n",
    "    for task in tasks:\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot=4, q_num=1)\n",
    "        pred, true = maml_infer(model, support_set, query_set[0], optimizer)\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true)\n",
    "\n",
    "        print(f\" Task: {task} | VALUE nodes predicted: {(pred == 1).sum().item()} | True: {(true == 1).sum().item()}\")\n",
    "\n",
    "    return all_preds, all_trues\n",
    "\n",
    "# # ---------- Main Runner ----------\n",
    "# if __name__ == \"__main__\":\n",
    "#     data_list = torch.load(\"fewshot_dataset.pt\", map_location=DEVICE)\n",
    "#     evaluate_model(data_list, model_path=\"maml_gat_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8b1c2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\2481703583.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data\\\\few-shot-dataset\\\\fewshot_dataset.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\222258546.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Task: Final Bill | VALUE nodes predicted: 0 | True: 0\n",
      " Task: Invoice | VALUE nodes predicted: 0 | True: 0\n",
      " Task: Loan | VALUE nodes predicted: 0 | True: 0\n",
      " Task: Operative Report | VALUE nodes predicted: 0 | True: 0\n",
      " Task: Background Verification | VALUE nodes predicted: 0 | True: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3,\n",
       "          3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0,\n",
       "          3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "          0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3,\n",
       "          0, 3, 3, 3, 0, 3, 3, 3, 3]),\n",
       "  tensor([0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0,\n",
       "          3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "          0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3]),\n",
       "  tensor([0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3,\n",
       "          3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3,\n",
       "          3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3,\n",
       "          3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "          0, 3, 3, 0, 3, 3, 3]),\n",
       "  tensor([0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3,\n",
       "          0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]),\n",
       "  tensor([0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3,\n",
       "          0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3,\n",
       "          0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3,\n",
       "          3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3])],\n",
       " [tensor([0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3,\n",
       "          3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0,\n",
       "          3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "          0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3,\n",
       "          0, 3, 3, 3, 0, 3, 3, 3, 3]),\n",
       "  tensor([0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0,\n",
       "          3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "          0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3]),\n",
       "  tensor([0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3,\n",
       "          3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3,\n",
       "          3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3,\n",
       "          3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "          0, 3, 3, 0, 3, 3, 3]),\n",
       "  tensor([0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3,\n",
       "          0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3]),\n",
       "  tensor([0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3,\n",
       "          0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3,\n",
       "          0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "          3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0,\n",
       "          3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3,\n",
       "          3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 3])])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = torch.load(\"data\\\\few-shot-dataset\\\\fewshot_dataset.pt\", map_location=DEVICE)\n",
    "evaluate_model(data_list, model_path=\"models\\maml_gat_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89a83454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Graph 1:\n",
      "‚úÖ Accuracy: 100.00% (113/113)\n",
      "üîç True VALUE node indices: []\n",
      "üîÆ Predicted VALUE node indices: []\n",
      "üéØ Correctly predicted VALUEs: 0 / 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\2248943374.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"models/maml_gat_model.pt\", map_location=DEVICE))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\2248943374.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graphs = torch.load(\"BG/datacheckpoint_11.pt\", map_location=DEVICE)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------- 1. Build the GAT Model ----------\n",
    "def build_gat_model(hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "    return GAT(\n",
    "        in_channels=18,\n",
    "        hidden_channels=hidden,\n",
    "        out_channels=4,\n",
    "        heads=heads,\n",
    "        num_layers=layers,\n",
    "        dropout=dropout,\n",
    "        edge_dim=1,\n",
    "        v2=True,\n",
    "        jk='lstm'  # or 'cat' if you trained with that\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# ----------- 2. Load Trained Model ----------\n",
    "model = build_gat_model()\n",
    "model.load_state_dict(torch.load(\"models/maml_gat_model.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# ----------- 3. Load Graphs with Labels ----------\n",
    "graphs = torch.load(\"BG/datacheckpoint_11.pt\", map_location=DEVICE)\n",
    "\n",
    "# ----------- 4. Predict + Compare ----------\n",
    "for i, graph in enumerate(graphs):\n",
    "    graph = graph.to(DEVICE)\n",
    "    true_labels = graph.y\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(graph.x, graph.edge_index, edge_weight=graph.edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    # Compare predictions\n",
    "    correct = (pred == true_labels).sum().item()\n",
    "    total = len(true_labels)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Value-specific analysis\n",
    "    true_value_indices = (true_labels == 1).nonzero(as_tuple=True)[0]\n",
    "    pred_value_indices = (pred == 1).nonzero(as_tuple=True)[0]\n",
    "    true_positive = len(set(pred_value_indices.tolist()) & set(true_value_indices.tolist()))\n",
    "\n",
    "    print(f\"\\nüìÑ Graph {i+1}:\")\n",
    "    print(f\"‚úÖ Accuracy: {accuracy*100:.2f}% ({correct}/{total})\")\n",
    "    print(f\"üîç True VALUE node indices: {true_value_indices.tolist()}\")\n",
    "    print(f\"üîÆ Predicted VALUE node indices: {pred_value_indices.tolist()}\")\n",
    "    print(f\"üéØ Correctly predicted VALUEs: {true_positive} / {len(true_value_indices)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENVGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
