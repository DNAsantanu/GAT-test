{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b322c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 5 files for task: Invoice\n",
      "üîç Processing 5 files for task: Loan\n",
      "üîç Processing 5 files for task: Final Bill\n",
      "üîç Processing 5 files for task: Background Verification\n",
      "üîç Processing 5 files for task: Operative Report\n",
      "Saved all 25 graphs to fewshot_dataset.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\2258181699.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Invoice\": \"data/invoice/\",\n",
    "    \"Loan\": \"data/loan/\",\n",
    "    \"Final Bill\": \"data/final_bill/\",\n",
    "    \"Background Verification\": \"data/background_verification/\",\n",
    "    \"Operative Report\": \"data/operative_report/\"\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/few-shot-dataset\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/few-shot-dataset/fewshot_dataset.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to fewshot_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74971e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Invoice\": \"data/invoice/\",\n",
    "    \"Loan\": \"data/loan/\",\n",
    "    \"Final Bill\": \"data/final_bill/\",\n",
    "    \"Background Verification\": \"data/background_verification/\",\n",
    "    \"Operative Report\": \"data/operative_report/\"\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/few-shot-dataset\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/few-shot-dataset/fewshot_dataset.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to fewshot_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7eb0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\1680026476.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\")\n"
     ]
    }
   ],
   "source": [
    "data_list = torch.load(\"data/few-shot-dataset/fewshot_dataset.pt\")\n",
    "print(data_list[0].task)  # should print \"Invoice\" or similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc399b08",
   "metadata": {},
   "source": [
    "### training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c26b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 5 files for task: Invoice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\3500537860.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 5 files for task: Loan\n",
      "üîç Processing 5 files for task: Final Bill\n",
      "Saved all 15 graphs to training_dataset.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Invoice\": \"data/invoice/\",\n",
    "    \"Loan\": \"data/loan/\",\n",
    "    \"Final Bill\": \"data/final_bill/\",\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/training_data\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/training_data/training_dataset.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to training_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46fdacb",
   "metadata": {},
   "source": [
    "### test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebb62787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing 5 files for task: Operative Report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\189357874.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(graph_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all 5 graphs to test_dataset.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define your document types and their data folder paths\n",
    "task_folders = {\n",
    "    \"Operative Report\": \"data/operative_report/\"\n",
    "}\n",
    "\n",
    "all_graphs = []\n",
    "\n",
    "for task_name, folder_path in task_folders.items():\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    graph_files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "\n",
    "    print(f\"üîç Processing {len(graph_files)} files for task: {task_name}\")\n",
    "    for file in graph_files:\n",
    "        graph_path = os.path.join(folder_path, file)\n",
    "        data = torch.load(graph_path)\n",
    "        if isinstance(data, list):\n",
    "           for d in data:\n",
    "               d.task = task_name\n",
    "               all_graphs.append(d)\n",
    "        else:\n",
    "            data.task = task_name\n",
    "            all_graphs.append(data)\n",
    "\n",
    "# Save to one master file\n",
    "os.makedirs(\"data/test_data\", exist_ok=True)\n",
    "torch.save(all_graphs, \"data/test_data/test_dataset.pt\")\n",
    "print(f\"Saved all {len(all_graphs)} graphs to test_dataset.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4edfe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maml_runner.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import higher\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "# ------------- Config -------------------\n",
    "IN_CHANNELS = 18\n",
    "OUT_CLASSES = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- GAT Model --------------------\n",
    "def build_gat_model(hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "    return GAT(\n",
    "        in_channels=IN_CHANNELS,\n",
    "        hidden_channels=hidden,\n",
    "        out_channels=OUT_CLASSES,\n",
    "        heads=heads,\n",
    "        num_layers=layers,\n",
    "        dropout=dropout,\n",
    "        edge_dim=1,\n",
    "        v2=True,\n",
    "        jk='lstm'\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# --------- Episode Sampler -------------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    assert len(task_data) >= k_shot + q_num, f\"Not enough data for task: {task}\"\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# --------- MAML Training Loop ----------\n",
    "def maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500):\n",
    "    model.train()\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        task = random.choice(tasks)\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot=4, q_num=1)\n",
    "\n",
    "        model.zero_grad()\n",
    "        with torch.backends.cudnn.flags(enabled=False):\n",
    "           with higher.innerloop_ctx(model, optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "           # Inner loop adaptation\n",
    "                for _ in range(inner_steps):\n",
    "                   for support in support_set:\n",
    "                       support = support.to(DEVICE)\n",
    "                       out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                       loss = F.cross_entropy(out, support.y)\n",
    "                       diffopt.step(loss)\n",
    "                # Outer loop: evaluate on query\n",
    "                query = query_set[0].to(DEVICE)\n",
    "                out = fmodel(query.x, query.edge_index, edge_weight=query.edge_attr)\n",
    "                loss = F.cross_entropy(out, query.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        if episode % 5 == 0:\n",
    "            print(f\"[Episode {episode}] Meta-loss: {loss.item():.4f} | Task: {task}\")\n",
    "\n",
    "# --------- MAML Inference -------------\n",
    "def maml_infer(model, support_set, query_doc, optimizer, inner_steps=1):\n",
    "    model.eval()\n",
    "\n",
    "    with higher.innerloop_ctx(model, optimizer, track_higher_grads=False) as (fmodel, diffopt):\n",
    "        # Adapt on support\n",
    "        for _ in range(inner_steps):\n",
    "            for support in support_set:\n",
    "                support = support.to(DEVICE)\n",
    "                out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                loss = F.cross_entropy(out, support.y)\n",
    "                diffopt.step(loss)\n",
    "\n",
    "        # Predict on query\n",
    "        query_doc = query_doc.to(DEVICE)\n",
    "        out = fmodel(query_doc.x, query_doc.edge_index, edge_weight=query_doc.edge_attr)\n",
    "        preds = out.argmax(dim=1)\n",
    "\n",
    "    return preds\n",
    "\n",
    "# # --------- Main Runner -----------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\" Loading few-shot dataset...\")\n",
    "#     data_list = torch.load(\"data\\few-shot-dataset\\fewshot_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "#     model = build_gat_model()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#     print(\" Starting MAML training...\")\n",
    "#     maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500)\n",
    "\n",
    "#     print(\" Saving MAML-trained model...\")\n",
    "#     torch.save(model.state_dict(), \"models\\maml_gat_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c8fd62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading few-shot dataset...\n",
      " Starting MAML training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\972535379.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data\\\\training_data\\\\training_dataset.pt\", map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] Meta-loss: 1.3665 | Task: Loan\n",
      "[Episode 5] Meta-loss: 1.2402 | Task: Invoice\n",
      "[Episode 10] Meta-loss: 1.0269 | Task: Final Bill\n",
      "[Episode 15] Meta-loss: 0.7736 | Task: Final Bill\n",
      "[Episode 20] Meta-loss: 0.6972 | Task: Final Bill\n",
      "[Episode 25] Meta-loss: 0.6492 | Task: Loan\n",
      "[Episode 30] Meta-loss: 0.5748 | Task: Loan\n",
      "[Episode 35] Meta-loss: 0.5713 | Task: Invoice\n",
      "[Episode 40] Meta-loss: 0.5569 | Task: Final Bill\n",
      "[Episode 45] Meta-loss: 0.5216 | Task: Loan\n",
      "[Episode 50] Meta-loss: 0.5076 | Task: Loan\n",
      "[Episode 55] Meta-loss: 0.4939 | Task: Loan\n",
      "[Episode 60] Meta-loss: 0.4591 | Task: Loan\n",
      "[Episode 65] Meta-loss: 0.4707 | Task: Invoice\n",
      "[Episode 70] Meta-loss: 0.4119 | Task: Final Bill\n",
      "[Episode 75] Meta-loss: 0.3307 | Task: Loan\n",
      "[Episode 80] Meta-loss: 0.2922 | Task: Loan\n",
      "[Episode 85] Meta-loss: 0.2252 | Task: Loan\n",
      "[Episode 90] Meta-loss: 0.1731 | Task: Loan\n",
      "[Episode 95] Meta-loss: 0.2738 | Task: Loan\n",
      "[Episode 100] Meta-loss: 0.0975 | Task: Final Bill\n",
      "[Episode 105] Meta-loss: 0.1776 | Task: Final Bill\n",
      "[Episode 110] Meta-loss: 0.0913 | Task: Loan\n",
      "[Episode 115] Meta-loss: 0.1177 | Task: Invoice\n",
      "[Episode 120] Meta-loss: 0.0682 | Task: Invoice\n",
      "[Episode 125] Meta-loss: 0.0416 | Task: Final Bill\n",
      "[Episode 130] Meta-loss: 0.0715 | Task: Invoice\n",
      "[Episode 135] Meta-loss: 0.0607 | Task: Final Bill\n",
      "[Episode 140] Meta-loss: 0.0983 | Task: Loan\n",
      "[Episode 145] Meta-loss: 0.0669 | Task: Final Bill\n",
      "[Episode 150] Meta-loss: 0.0315 | Task: Invoice\n",
      "[Episode 155] Meta-loss: 0.0172 | Task: Loan\n",
      "[Episode 160] Meta-loss: 0.0227 | Task: Invoice\n",
      "[Episode 165] Meta-loss: 0.0122 | Task: Loan\n",
      "[Episode 170] Meta-loss: 0.0150 | Task: Final Bill\n",
      "[Episode 175] Meta-loss: 0.0162 | Task: Invoice\n",
      "[Episode 180] Meta-loss: 0.0310 | Task: Invoice\n",
      "[Episode 185] Meta-loss: 0.0077 | Task: Loan\n",
      "[Episode 190] Meta-loss: 0.0091 | Task: Invoice\n",
      "[Episode 195] Meta-loss: 0.0067 | Task: Loan\n",
      "[Episode 200] Meta-loss: 0.0280 | Task: Loan\n",
      "[Episode 205] Meta-loss: 0.0235 | Task: Final Bill\n",
      "[Episode 210] Meta-loss: 0.0107 | Task: Invoice\n",
      "[Episode 215] Meta-loss: 0.0105 | Task: Loan\n",
      "[Episode 220] Meta-loss: 0.0136 | Task: Loan\n",
      "[Episode 225] Meta-loss: 0.0201 | Task: Final Bill\n",
      "[Episode 230] Meta-loss: 0.0234 | Task: Loan\n",
      "[Episode 235] Meta-loss: 0.0130 | Task: Final Bill\n",
      "[Episode 240] Meta-loss: 0.0018 | Task: Loan\n",
      "[Episode 245] Meta-loss: 0.0217 | Task: Final Bill\n",
      "[Episode 250] Meta-loss: 0.0043 | Task: Final Bill\n",
      "[Episode 255] Meta-loss: 0.0170 | Task: Invoice\n",
      "[Episode 260] Meta-loss: 0.0084 | Task: Final Bill\n",
      "[Episode 265] Meta-loss: 0.0021 | Task: Final Bill\n",
      "[Episode 270] Meta-loss: 0.0064 | Task: Invoice\n",
      "[Episode 275] Meta-loss: 0.0028 | Task: Loan\n",
      "[Episode 280] Meta-loss: 0.0227 | Task: Loan\n",
      "[Episode 285] Meta-loss: 0.0012 | Task: Loan\n",
      "[Episode 290] Meta-loss: 0.0165 | Task: Final Bill\n",
      "[Episode 295] Meta-loss: 0.0022 | Task: Loan\n",
      "[Episode 300] Meta-loss: 0.0029 | Task: Invoice\n",
      "[Episode 305] Meta-loss: 0.0005 | Task: Loan\n",
      "[Episode 310] Meta-loss: 0.0148 | Task: Invoice\n",
      "[Episode 315] Meta-loss: 0.0024 | Task: Loan\n",
      "[Episode 320] Meta-loss: 0.0008 | Task: Loan\n",
      "[Episode 325] Meta-loss: 0.0027 | Task: Loan\n",
      "[Episode 330] Meta-loss: 0.0080 | Task: Final Bill\n",
      "[Episode 335] Meta-loss: 0.0105 | Task: Invoice\n",
      "[Episode 340] Meta-loss: 0.0006 | Task: Loan\n",
      "[Episode 345] Meta-loss: 0.0006 | Task: Final Bill\n",
      "[Episode 350] Meta-loss: 0.0097 | Task: Invoice\n",
      "[Episode 355] Meta-loss: 0.0035 | Task: Invoice\n",
      "[Episode 360] Meta-loss: 0.0114 | Task: Final Bill\n",
      "[Episode 365] Meta-loss: 0.0043 | Task: Final Bill\n",
      "[Episode 370] Meta-loss: 0.0030 | Task: Invoice\n",
      "[Episode 375] Meta-loss: 0.0055 | Task: Final Bill\n",
      "[Episode 380] Meta-loss: 0.0001 | Task: Final Bill\n",
      "[Episode 385] Meta-loss: 0.0049 | Task: Invoice\n",
      "[Episode 390] Meta-loss: 0.0016 | Task: Loan\n",
      "[Episode 395] Meta-loss: 0.0025 | Task: Final Bill\n",
      "[Episode 400] Meta-loss: 0.0064 | Task: Loan\n",
      "[Episode 405] Meta-loss: 0.0004 | Task: Final Bill\n",
      "[Episode 410] Meta-loss: 0.0255 | Task: Loan\n",
      "[Episode 415] Meta-loss: 0.0073 | Task: Final Bill\n",
      "[Episode 420] Meta-loss: 0.0006 | Task: Loan\n",
      "[Episode 425] Meta-loss: 0.0494 | Task: Invoice\n",
      "[Episode 430] Meta-loss: 0.0096 | Task: Invoice\n",
      "[Episode 435] Meta-loss: 0.0012 | Task: Invoice\n",
      "[Episode 440] Meta-loss: 0.0103 | Task: Loan\n",
      "[Episode 445] Meta-loss: 0.0065 | Task: Invoice\n",
      "[Episode 450] Meta-loss: 0.0006 | Task: Final Bill\n",
      "[Episode 455] Meta-loss: 0.0290 | Task: Invoice\n",
      "[Episode 460] Meta-loss: 0.0095 | Task: Loan\n",
      "[Episode 465] Meta-loss: 0.0129 | Task: Loan\n",
      "[Episode 470] Meta-loss: 0.0027 | Task: Loan\n",
      "[Episode 475] Meta-loss: 0.0014 | Task: Final Bill\n",
      "[Episode 480] Meta-loss: 0.0037 | Task: Loan\n",
      "[Episode 485] Meta-loss: 0.0004 | Task: Invoice\n",
      "[Episode 490] Meta-loss: 0.0003 | Task: Final Bill\n",
      "[Episode 495] Meta-loss: 0.0004 | Task: Invoice\n",
      " Saving MAML-trained model...\n"
     ]
    }
   ],
   "source": [
    "print(\" Loading few-shot dataset...\")\n",
    "data_list = torch.load(\"data\\\\training_data\\\\training_dataset.pt\", map_location=DEVICE)\n",
    "\n",
    "model = build_gat_model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(\" Starting MAML training...\")\n",
    "maml_train(data_list, model, optimizer, inner_steps=1, n_episodes=500)\n",
    "\n",
    "print(\" Saving MAML-trained model...\")\n",
    "torch.save(model.state_dict(), \"models\\maml\\maml_gat_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maml_evaluator.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GAT\n",
    "import higher\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- GAT Builder (same config as maml_runner) ----------\n",
    "def build_gat_model(hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "    return GAT(\n",
    "        in_channels=18,\n",
    "        hidden_channels=hidden,\n",
    "        out_channels=4,\n",
    "        heads=heads,\n",
    "        num_layers=layers,\n",
    "        dropout=dropout,\n",
    "        edge_dim=1,\n",
    "        v2=True,\n",
    "        jk='lstm'\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# ---------- Episode Sampler ----------\n",
    "def sample_episode(data_list, task, k_shot=4, q_num=1):\n",
    "    task_data = [d for d in data_list if getattr(d, 'task', None) == task]\n",
    "    random.shuffle(task_data)\n",
    "    return task_data[:k_shot], task_data[k_shot:k_shot + q_num]\n",
    "\n",
    "# ---------- Inference Logic ----------\n",
    "def maml_infer(model, support_set, query_doc, optimizer, inner_steps=1):\n",
    "    model.train()\n",
    "\n",
    "    with higher.innerloop_ctx(model, optimizer, track_higher_grads=False) as (fmodel, diffopt):\n",
    "        for _ in range(inner_steps):\n",
    "            for support in support_set:\n",
    "                support = support.to(DEVICE)\n",
    "                out = fmodel(support.x, support.edge_index, edge_weight=support.edge_attr)\n",
    "                loss = F.cross_entropy(out, support.y)\n",
    "                diffopt.step(loss)\n",
    "\n",
    "        query_doc = query_doc.to(DEVICE)\n",
    "        out = fmodel(query_doc.x, query_doc.edge_index, edge_weight=query_doc.edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    return pred.cpu(), query_doc.y.cpu()\n",
    "\n",
    "# ---------- Evaluation Loop ----------\n",
    "def evaluate_model(data_list, model_path):\n",
    "    print(\"üîç Loading model...\")\n",
    "    model = build_gat_model()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    tasks = list(set(d.task for d in data_list))\n",
    "    all_preds, all_trues = [], []\n",
    "\n",
    "    for task in tasks:\n",
    "        support_set, query_set = sample_episode(data_list, task, k_shot=4, q_num=1)\n",
    "        pred, true = maml_infer(model, support_set, query_set[0], optimizer)\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true)\n",
    "\n",
    "        # Print detection for all labels\n",
    "        unique_labels = set(true.tolist())\n",
    "        detected_labels = set(pred.tolist())\n",
    "        print(f\" Task: {task}\")\n",
    "        print(f\"  True labels present: {sorted(unique_labels)}\")\n",
    "        print(f\"  Predicted labels present: {sorted(detected_labels)}\")\n",
    "        missing_labels = unique_labels - detected_labels\n",
    "        if missing_labels:\n",
    "            print(f\"  ‚ùå Missing labels in prediction: {sorted(missing_labels)}\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ All true labels detected in prediction.\")\n",
    "\n",
    "        print(f\"  VALUE nodes predicted: {(pred == 1).sum().item()} | True: {(true == 1).sum().item()}\")\n",
    "\n",
    "        # Print classification report for this query\n",
    "        print(classification_report(true, pred, zero_division=0))\n",
    "\n",
    "    # Optionally, print overall classification report\n",
    "    all_preds_flat = torch.cat(all_preds).numpy()\n",
    "    all_trues_flat = torch.cat(all_trues).numpy()\n",
    "    print(\"\\n===== Overall Classification Report (all tasks) =====\")\n",
    "    print(classification_report(all_trues_flat, all_preds_flat, zero_division=0))\n",
    "\n",
    "    return all_preds, all_trues\n",
    "\n",
    "# # ---------- Main Runner ----------\n",
    "# if __name__ == \"__main__\":\n",
    "#     data_list = torch.load(\"fewshot_dataset.pt\", map_location=DEVICE)\n",
    "#     evaluate_model(data_list, model_path=\"maml_gat_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8b1c2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\4139781609.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_list = torch.load(\"data\\\\test_data\\\\test_dataset.pt\", map_location=DEVICE)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\222258546.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading model...\n",
      " Task: Operative Report | VALUE nodes predicted: 0 | True: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3,\n",
       "          3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3,\n",
       "          3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3])],\n",
       " [tensor([0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3,\n",
       "          3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3,\n",
       "          3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3])])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = torch.load(\"data\\\\test_data\\\\test_dataset.pt\", map_location=DEVICE)\n",
    "evaluate_model(data_list, model_path=\"models\\maml\\maml_gat_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89a83454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Graph 1:\n",
      "‚úÖ Accuracy: 100.00% (113/113)\n",
      "üîç True VALUE node indices: []\n",
      "üîÆ Predicted VALUE node indices: []\n",
      "üéØ Correctly predicted VALUEs: 0 / 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\2248943374.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"models/maml_gat_model.pt\", map_location=DEVICE))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_24384\\2248943374.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graphs = torch.load(\"BG/datacheckpoint_11.pt\", map_location=DEVICE)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GAT\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----------- 1. Build the GAT Model ----------\n",
    "def build_gat_model(hidden=128, heads=4, dropout=0.2, layers=2):\n",
    "    return GAT(\n",
    "        in_channels=18,\n",
    "        hidden_channels=hidden,\n",
    "        out_channels=4,\n",
    "        heads=heads,\n",
    "        num_layers=layers,\n",
    "        dropout=dropout,\n",
    "        edge_dim=1,\n",
    "        v2=True,\n",
    "        jk='lstm'  # or 'cat' if you trained with that\n",
    "    ).to(DEVICE)\n",
    "\n",
    "# ----------- 2. Load Trained Model ----------\n",
    "model = build_gat_model()\n",
    "model.load_state_dict(torch.load(\"models/maml_gat_model.pt\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# ----------- 3. Load Graphs with Labels ----------\n",
    "graphs = torch.load(\"BG/datacheckpoint_11.pt\", map_location=DEVICE)\n",
    "\n",
    "# ----------- 4. Predict + Compare ----------\n",
    "for i, graph in enumerate(graphs):\n",
    "    graph = graph.to(DEVICE)\n",
    "    true_labels = graph.y\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(graph.x, graph.edge_index, edge_weight=graph.edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    # Compare predictions\n",
    "    correct = (pred == true_labels).sum().item()\n",
    "    total = len(true_labels)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Value-specific analysis\n",
    "    true_value_indices = (true_labels == 1).nonzero(as_tuple=True)[0]\n",
    "    pred_value_indices = (pred == 1).nonzero(as_tuple=True)[0]\n",
    "    true_positive = len(set(pred_value_indices.tolist()) & set(true_value_indices.tolist()))\n",
    "\n",
    "    print(f\"\\nüìÑ Graph {i+1}:\")\n",
    "    print(f\"‚úÖ Accuracy: {accuracy*100:.2f}% ({correct}/{total})\")\n",
    "    print(f\"üîç True VALUE node indices: {true_value_indices.tolist()}\")\n",
    "    print(f\"üîÆ Predicted VALUE node indices: {pred_value_indices.tolist()}\")\n",
    "    print(f\"üéØ Correctly predicted VALUEs: {true_positive} / {len(true_value_indices)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENVGAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
